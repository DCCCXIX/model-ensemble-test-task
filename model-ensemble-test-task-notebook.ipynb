{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"model ensemble test task.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В колабе представлен стакинг с помощью усреднения, он дает 121 ошибок\n",
        "\n",
        "Икс - это выходы обученных моделей, игрек - это классы\n",
        "\n",
        "Задача представить решение лучше"
      ],
      "metadata": {
        "id": "R3jjsv50OoLF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "source": [
        "%%bash\r\n",
        "wget -q https://dl.min.io/client/mc/release/linux-amd64/mc\r\n",
        "chmod +x mc\r\n",
        "./mc config host add new https://gos.amai.io:443"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added `new` successfully.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuEhbNp9xQ5e",
        "outputId": "c95496a8-a3f2-44e0-c0fa-d9a860628f5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "source": [
        "!./mc cp --recursive new/amai-models-pub/test_task/ ./"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`new/amai-models-pub/test_task/y_test_task.pkl` -> `y_test_task.pkl`\n",
            "`new/amai-models-pub/test_task/x_test_task.pkl` -> `x_test_task.pkl`\n",
            "Total: 0 B, Transferred: 3.67 MiB, Speed: 35.00 MiB/s\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmN5d7pExa-m",
        "outputId": "f88033e7-ddfb-46ef-a806-db94f1a287ea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "source": [
        "!pip install catboost\r\n",
        "!pip install ipywidgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.26.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.0.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPEcSWg0QqpS",
        "outputId": "9fb68ae4-43b9-4d38-cad3-2c4ae466ab59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "source": [
        "!pip install catalyst"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catalyst in /usr/local/lib/python3.7/dist-packages (21.7)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (4.62.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from catalyst) (5.4.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.9.0+cu102)\n",
            "Requirement already satisfied: tensorboardX<2.3.0>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (2.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX<2.3.0>=2.1.0->catalyst) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX<2.3.0>=2.1.0->catalyst) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->catalyst) (3.7.4.3)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBx05OVDcUbe",
        "outputId": "84e99b1d-408b-4b62-d971-8b95829a9ade"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "source": [
        "import pickle\r\n",
        "with open('x_test_task.pkl', 'rb') as f:\r\n",
        "    x = pickle.load(f)\r\n",
        "with open('y_test_task.pkl', 'rb') as f:\r\n",
        "    y = pickle.load(f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "x9AMO9RZ2xtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "source": [
        "# importing numerous libs for various types of solutions\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import os\r\n",
        "import copy\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import catboost\r\n",
        "from catboost import Pool, CatBoostClassifier\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n",
        "from catalyst.data.sampler import BalanceClassSampler\r\n",
        "\r\n",
        "# seed everything for reproducibility\r\n",
        "SEED = 666\r\n",
        "random.seed(SEED)\r\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "outputs": [],
      "metadata": {
        "id": "TXTEP1DNZr_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "source": [
        "def get_metrics(y, preds):\n",
        "  accuracy = accuracy_score(y, preds)\n",
        "  macro_f1 = f1_score(y, preds, average=\"macro\")\n",
        "\n",
        "  return accuracy, macro_f1\n",
        "\n",
        "def simple_stacking(x, y):\n",
        "  num_errors_mean = sum(abs(np.mean(x, -1).round() - y))\n",
        "  num_errors_median = sum(abs(np.median(x, -1).round() - y))\n",
        "  num_errors_combined = (np.mean(x, -1)+np.median(x, -1))/2\n",
        "  num_errors_combined = sum(abs(num_errors_combined.round()-y))\n",
        "  simple_preds = ((np.mean(x, -1)+np.median(x, -1))/2).round()\n",
        "\n",
        "  accuracy, macro_f1 = get_metrics(y, simple_preds)\n",
        "\n",
        "  return f\"Amount of errors with mean based stacking: {num_errors_mean}\\n\\\n",
        "          Amount of errors with median based stacking: {num_errors_median}\\n\\\n",
        "          Amount of errors with combined stacking: {num_errors_combined}\\n\\\n",
        "          Accuracy: {accuracy} Macro F1: {macro_f1}\"\n",
        "\n",
        "print(simple_stacking(x, y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of errors with mean based stacking: 121.0\n",
            "          Amount of errors with median based stacking: 120.0\n",
            "          Amount of errors with combined stacking: 117.0\n",
            "          Accuracy: 0.9986616334934798 Macro F1: 0.997221892898418\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UsPx-6OZgm8",
        "outputId": "a9c1e8e6-1a10-4e85-934d-845ce072197e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "source": [
        "# simple stacking provides 117 errors out of  87420 samples\n",
        "# which is 99.99866~ accuracy to improve upon and 0.99722 macro F1"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gkzm4JIiQvoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "source": [
        "# checking label balance\n",
        "np.unique(y, return_counts=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([75181, 12239]))"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ci8bszeuKm",
        "outputId": "2baeafbc-78ea-4a7a-83f5-25848296b23b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "source": [
        "# def generate_features(x):\n",
        "#   mean_col = np.mean(x, -1, keepdims=True)\n",
        "#   median_col = np.median(x, -1, keepdims=True)\n",
        "#   combined_col = ((np.mean(x, -1, keepdims=True)+np.median(x, -1, keepdims=True))/2)\n",
        "#   x = np.append(x, mean_col, 1)\n",
        "#   x = np.append(x, median_col, 1)\n",
        "#   x = np.append(x, combined_col, 1)\n",
        "\n",
        "#   return x\n",
        "\n",
        "# x = generate_features(x)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6RgYWgJMnzeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.5, random_state=SEED)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7yQ7X5EEdb4s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "source": [
        "clf = SVC(random_state=SEED)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "preds = clf.predict(x_valid)\n",
        "x_valid.shape[0]-np.count_nonzero(preds==y_valid)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-lPMZ72MQow",
        "outputId": "3621b803-faeb-4293-9299-8bcd0957643a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "source": [
        "accuracy, macro_f1 = get_metrics(y_valid, preds)\n",
        "print(f\"Accuracy: {accuracy} Macro F1: {macro_f1}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9988332189430337 Macro F1: 0.9975976520402126\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt9g2tkrVTtA",
        "outputId": "a8c407ad-19dc-4216-ecfb-f99ef9f8b3d1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "source": [
        "print(confusion_matrix(y_valid, preds))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[37503    31]\n",
            " [   20  6156]]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3D3_E-HM9qX",
        "outputId": "f0844e8f-ad98-4be2-a9bc-8f2a4dce6dc3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "source": [
        "# marginal increase in accuracy/f1"
      ],
      "outputs": [],
      "metadata": {
        "id": "v9CyguAJWDup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "source": [
        "# hyperparameters\n",
        "params = {\n",
        "    \"iterations\" : 2000,\n",
        "    #\"auto_class_weights\" : \"Balanced\",\n",
        "    # heavily favors minority class with auto_class_weights\n",
        "    \"bootstrap_type\" : \"Bernoulli\",\n",
        "    \"subsample\" : 0.5,\n",
        "    \"depth\" : 1, #7\n",
        "    #\"task_type\" : \"GPU\",\n",
        "    \"learning_rate\" : 0.005,\n",
        "    #\"l2_leaf_reg\" : 0,\n",
        "    \"loss_function\" : \"Logloss\",\n",
        "    \"eval_metric\" : \"TotalF1\",\n",
        "    \"random_seed\" : SEED,\n",
        "    \"verbose\" : True,\n",
        "    \"metric_period\" : 100\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "PrBPfVSbdtcD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "source": [
        "train_data = Pool(data=x_train,\n",
        "                  label=y_train,                \n",
        "                )\n",
        "\n",
        "valid_data = Pool(data=x_valid,\n",
        "                  label=y_valid,\n",
        "                )\n",
        "\n",
        "model = CatBoostClassifier(**params)\n",
        "model.fit(train_data, eval_set = valid_data, plot = False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.9961175\ttest: 0.9969262\tbest: 0.9969262 (0)\ttotal: 17.6ms\tremaining: 35.1s\n",
            "100:\tlearn: 0.9985117\ttest: 0.9986961\tbest: 0.9986961 (100)\ttotal: 1.07s\tremaining: 20.2s\n",
            "200:\tlearn: 0.9985349\ttest: 0.9987650\tbest: 0.9987650 (200)\ttotal: 2.04s\tremaining: 18.3s\n",
            "300:\tlearn: 0.9986268\ttest: 0.9988339\tbest: 0.9988339 (300)\ttotal: 2.99s\tremaining: 16.9s\n",
            "400:\tlearn: 0.9986727\ttest: 0.9988340\tbest: 0.9988340 (400)\ttotal: 3.9s\tremaining: 15.5s\n",
            "500:\tlearn: 0.9986499\ttest: 0.9988340\tbest: 0.9988340 (400)\ttotal: 4.8s\tremaining: 14.4s\n",
            "600:\tlearn: 0.9986270\ttest: 0.9988111\tbest: 0.9988340 (400)\ttotal: 5.71s\tremaining: 13.3s\n",
            "700:\tlearn: 0.9986270\ttest: 0.9988111\tbest: 0.9988340 (400)\ttotal: 6.57s\tremaining: 12.2s\n",
            "800:\tlearn: 0.9985814\ttest: 0.9988112\tbest: 0.9988340 (400)\ttotal: 7.44s\tremaining: 11.1s\n",
            "900:\tlearn: 0.9985814\ttest: 0.9988341\tbest: 0.9988341 (900)\ttotal: 8.36s\tremaining: 10.2s\n",
            "1000:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 9.22s\tremaining: 9.2s\n",
            "1100:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 10.1s\tremaining: 8.22s\n",
            "1200:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 10.9s\tremaining: 7.24s\n",
            "1300:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 11.7s\tremaining: 6.28s\n",
            "1400:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 12.5s\tremaining: 5.35s\n",
            "1500:\tlearn: 0.9985814\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 13.3s\tremaining: 4.43s\n",
            "1600:\tlearn: 0.9986042\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 14.1s\tremaining: 3.52s\n",
            "1700:\tlearn: 0.9986042\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 15s\tremaining: 2.64s\n",
            "1800:\tlearn: 0.9986042\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 15.9s\tremaining: 1.75s\n",
            "1900:\tlearn: 0.9986042\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 16.8s\tremaining: 873ms\n",
            "1999:\tlearn: 0.9986042\ttest: 0.9988570\tbest: 0.9988570 (1000)\ttotal: 17.7s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.9988570232\n",
            "bestIteration = 1000\n",
            "\n",
            "Shrink model to first 1001 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f7c609986d0>"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzU85uSleL5B",
        "outputId": "f2e3d3ed-b880-4c23-a168-2e6ca37eed4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "source": [
        "cv_params = model.get_params()\n",
        "cv_data = catboost.cv(\n",
        "                  Pool(x, y),\n",
        "                  params,\n",
        "                  fold_count=5,\n",
        "                  )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.9970972\ttest: 0.9970569\tbest: 0.9970569 (0)\n",
            "100:\tlearn: 0.9984664\ttest: 0.9984434\tbest: 0.9984434 (100)\n",
            "200:\tlearn: 0.9985612\ttest: 0.9985582\tbest: 0.9985582 (200)\ttotal: 16.8s\tremaining: 2m 30s\n",
            "300:\tlearn: 0.9986329\ttest: 0.9985927\tbest: 0.9985927 (300)\n",
            "400:\tlearn: 0.9986645\ttest: 0.9986042\tbest: 0.9986042 (400)\n",
            "500:\tlearn: 0.9986674\ttest: 0.9986158\tbest: 0.9986158 (500)\n",
            "600:\tlearn: 0.9986674\ttest: 0.9986158\tbest: 0.9986158 (500)\n",
            "700:\tlearn: 0.9986703\ttest: 0.9985929\tbest: 0.9986158 (500)\n",
            "800:\tlearn: 0.9986646\ttest: 0.9986044\tbest: 0.9986158 (500)\n",
            "900:\tlearn: 0.9986646\ttest: 0.9986159\tbest: 0.9986159 (900)\n",
            "1000:\tlearn: 0.9986703\ttest: 0.9986159\tbest: 0.9986159 (900)\n",
            "1100:\tlearn: 0.9986789\ttest: 0.9986159\tbest: 0.9986159 (900)\n",
            "1200:\tlearn: 0.9986818\ttest: 0.9986159\tbest: 0.9986159 (900)\n",
            "1300:\tlearn: 0.9986818\ttest: 0.9986159\tbest: 0.9986159 (900)\ttotal: 1m 35s\tremaining: 51.2s\n",
            "1400:\tlearn: 0.9986760\ttest: 0.9986388\tbest: 0.9986388 (1400)\n",
            "1500:\tlearn: 0.9986846\ttest: 0.9986388\tbest: 0.9986388 (1400)\n",
            "1600:\tlearn: 0.9986818\ttest: 0.9986273\tbest: 0.9986388 (1400)\n",
            "1700:\tlearn: 0.9986818\ttest: 0.9986273\tbest: 0.9986388 (1400)\n",
            "1800:\tlearn: 0.9986760\ttest: 0.9986274\tbest: 0.9986388 (1400)\n",
            "1900:\tlearn: 0.9986760\ttest: 0.9986274\tbest: 0.9986388 (1400)\n",
            "1999:\tlearn: 0.9986875\ttest: 0.9986274\tbest: 0.9986388 (1400)\ttotal: 2m 23s\tremaining: 0us\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGo-sPZKgVGk",
        "outputId": "ed0dcc09-cf63-4245-fd06-19897bddc699"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "source": [
        "print(f\"Best validation total F1 score: {np.max(cv_data['test-TotalF1-mean'])}±\\\n",
        "    {cv_data['test-TotalF1-std'][np.argmax(cv_data['test-TotalF1-mean'])]}\\\n",
        "    on step {np.argmax(cv_data['test-TotalF1-mean'])}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation total F1 score: 0.9986387729697727±    0.0003170138462593982    on step 14\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz8dO05egc5E",
        "outputId": "2b67e19a-91be-471b-9d9a-62c6302d750b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "source": [
        "preds = model.predict(x_valid)\n",
        "accuracy, macro_f1 = get_metrics(y_valid, preds)\n",
        "print(f\"Accuracy: {accuracy} Macro F1: {macro_f1}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9988560970029742 Macro F1: 0.9976468233228188\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX6WVTlTl-We",
        "outputId": "fc1df132-b87c-4b7a-b030-3ba4fccbfe6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "source": [
        "print(confusion_matrix(y_valid, preds))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[37497    37]\n",
            " [   13  6163]]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIXQ9lFaNjhv",
        "outputId": "f312ebfe-79d1-4ece-96c4-8e333ba4fcc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    logging.info(f'Running on {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.00005\n",
        "epochs = 20\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size=x.shape[1], output_size=2):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, output_size) \n",
        "\n",
        "        self.dropout = nn.Dropout(0.05)   \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iiVeUPogNmmy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        self.data = torch.from_numpy(x)\n",
        "        self.labels = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):        \n",
        "        sample, label = self.data[index], self.labels[index]\n",
        "\n",
        "        return sample, label\n",
        "\n",
        "train_dataset, valid_dataset = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cnYz21drPjqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "source": [
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler=BalanceClassSampler(y_train, mode = \"upsampling\"),\n",
        "            #sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "            valid_dataset,\n",
        "            sampler = SequentialSampler(valid_dataset),\n",
        "            batch_size = batch_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "wb48arOwPruP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr = learning_rate, weight_decay = 0.999, betas = (0.9, 0.999))\n",
        "\n",
        "def training_loop(epochs = epochs, net = net):\n",
        "    best_model_wts = copy.deepcopy(net.state_dict())\n",
        "    best_loss = 100\n",
        "    \n",
        "    for epoch in (range(epochs)):\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        train_losses, train_accuracies = train(net)        \n",
        "        val_losses, val_accuracies = validate(net)        \n",
        "        print(f'Training accuracy:   {sum(train_accuracies)/len(train_accuracies)} | Training loss: {sum(train_losses)/len(train_losses)}')\n",
        "        print(f'Validation accuracy: {sum(val_accuracies)/len(val_accuracies)} | Validation loss: {sum(val_losses)/len(val_losses)}')\n",
        "        \n",
        "        epoch_val_loss = sum(val_losses)/len(val_losses)\n",
        "        \n",
        "        if best_loss > epoch_val_loss:    \n",
        "            best_loss = epoch_val_loss\n",
        "            best_model_wts = copy.deepcopy(net.state_dict())\n",
        "            torch.save(net.state_dict(), 'best.pth')\n",
        "            print('saving with loss of {}'.format(epoch_val_loss), 'improved over previous {}'.format(best_loss))"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fw1_0V80PxZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "source": [
        "def fwd_pass(X, y, step, train = False):           \n",
        "    outputs = net(X)\n",
        "    matches = [torch.argmax(i) == j for i, j in zip(outputs,y)]        \n",
        "    acc = matches.count(True)/len(matches)\n",
        "    loss = loss_function(outputs, y)\n",
        "    if train:\n",
        "        loss.backward()        \n",
        "        optimizer.step()        \n",
        "        optimizer.zero_grad()\n",
        "    return acc, loss\n",
        "\n",
        "def train(net):\n",
        "    net.train()\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    print(\"Training\")\n",
        "    for step, batch in (enumerate(train_dataloader)):\n",
        "        inputs = batch[0].to(device).float()\n",
        "        labels = batch[1].to(device).long()    \n",
        "        acc, loss = fwd_pass(inputs, labels, step, train = True)\n",
        "        if step > 0 and step % 50 == 0:            \n",
        "            print(f\"Step {step} of {len(train_dataloader)}, Accuracy: {sum(train_accuracies)/len(train_accuracies)}, Loss: {sum(train_losses)/len(train_losses)}\")\n",
        "               \n",
        "        train_losses.append(loss)\n",
        "        train_accuracies.append(acc)\n",
        "    return train_losses, train_accuracies               \n",
        "                \n",
        "def validate(net):    \n",
        "    net.eval()\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    print(\"Validation\")\n",
        "    for step, batch in enumerate(valid_dataloader):            \n",
        "        valid_inputs = batch[0].to(device).float()\n",
        "        valid_labels = batch[1].to(device).long()\n",
        "    with torch.no_grad():\n",
        "        val_acc, val_loss =  fwd_pass(valid_inputs, valid_labels, step, train = False)\n",
        "        \n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)        \n",
        "    return val_losses, val_accuracies"
      ],
      "outputs": [],
      "metadata": {
        "id": "1fuqv4PJP4Qa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "source": [
        "training_loop(50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.843125, Loss: 0.6607733964920044\n",
            "Step 100 of 1177, Accuracy: 0.92015625, Loss: 0.6074382066726685\n",
            "Step 150 of 1177, Accuracy: 0.9454166666666667, Loss: 0.5413172841072083\n",
            "Step 200 of 1177, Accuracy: 0.9584375, Loss: 0.4698528051376343\n",
            "Step 250 of 1177, Accuracy: 0.966125, Loss: 0.4043361246585846\n",
            "Step 300 of 1177, Accuracy: 0.9711979166666667, Loss: 0.35051238536834717\n",
            "Step 350 of 1177, Accuracy: 0.9748214285714286, Loss: 0.3074113726615906\n",
            "Step 400 of 1177, Accuracy: 0.9776171875, Loss: 0.2731604278087616\n",
            "Step 450 of 1177, Accuracy: 0.9798263888888888, Loss: 0.24559831619262695\n",
            "Step 500 of 1177, Accuracy: 0.9816875, Loss: 0.22278475761413574\n",
            "Step 550 of 1177, Accuracy: 0.9830113636363637, Loss: 0.20431318879127502\n",
            "Step 600 of 1177, Accuracy: 0.9842708333333333, Loss: 0.18830394744873047\n",
            "Step 650 of 1177, Accuracy: 0.9852163461538461, Loss: 0.1750347763299942\n",
            "Step 700 of 1177, Accuracy: 0.9860267857142857, Loss: 0.1634148508310318\n",
            "Step 750 of 1177, Accuracy: 0.9868333333333333, Loss: 0.15310581028461456\n",
            "Step 800 of 1177, Accuracy: 0.98744140625, Loss: 0.14437928795814514\n",
            "Step 850 of 1177, Accuracy: 0.9879963235294118, Loss: 0.1365116983652115\n",
            "Step 900 of 1177, Accuracy: 0.9884895833333334, Loss: 0.12959003448486328\n",
            "Step 950 of 1177, Accuracy: 0.9889802631578948, Loss: 0.12326742708683014\n",
            "Step 1000 of 1177, Accuracy: 0.989375, Loss: 0.11766429990530014\n",
            "Step 1050 of 1177, Accuracy: 0.9897470238095238, Loss: 0.11255393177270889\n",
            "Step 1100 of 1177, Accuracy: 0.9900994318181818, Loss: 0.10792486369609833\n",
            "Step 1150 of 1177, Accuracy: 0.9904619565217392, Loss: 0.10353533923625946\n",
            "Validation\n",
            "Training accuracy:   0.9906409303313509 | Training loss: 0.10129069536924362\n",
            "Validation accuracy: 1.0 | Validation loss: 0.002449659863486886\n",
            "saving with loss of 0.002449659863486886 improved over previous 0.002449659863486886\n",
            "Epoch 2\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.007360822521150112\n",
            "Step 100 of 1177, Accuracy: 0.99765625, Loss: 0.008810630068182945\n",
            "Step 150 of 1177, Accuracy: 0.9975, Loss: 0.008665520697832108\n",
            "Step 200 of 1177, Accuracy: 0.9975, Loss: 0.008632415905594826\n",
            "Step 250 of 1177, Accuracy: 0.9973125, Loss: 0.009084830060601234\n",
            "Step 300 of 1177, Accuracy: 0.99734375, Loss: 0.009640981443226337\n",
            "Step 350 of 1177, Accuracy: 0.9973214285714286, Loss: 0.010103787295520306\n",
            "Step 400 of 1177, Accuracy: 0.9975, Loss: 0.009588615037500858\n",
            "Step 450 of 1177, Accuracy: 0.9973611111111111, Loss: 0.009380212053656578\n",
            "Step 500 of 1177, Accuracy: 0.99746875, Loss: 0.00920744240283966\n",
            "Step 550 of 1177, Accuracy: 0.9974431818181818, Loss: 0.009304990991950035\n",
            "Step 600 of 1177, Accuracy: 0.9975260416666667, Loss: 0.00899023562669754\n",
            "Step 650 of 1177, Accuracy: 0.9974519230769231, Loss: 0.0091874860227108\n",
            "Step 700 of 1177, Accuracy: 0.9975, Loss: 0.009115980006754398\n",
            "Step 750 of 1177, Accuracy: 0.9974791666666667, Loss: 0.009037449955940247\n",
            "Step 800 of 1177, Accuracy: 0.99734375, Loss: 0.009418242610991001\n",
            "Step 850 of 1177, Accuracy: 0.9972610294117648, Loss: 0.009480186738073826\n",
            "Step 900 of 1177, Accuracy: 0.9972048611111111, Loss: 0.009507580660283566\n",
            "Step 950 of 1177, Accuracy: 0.9972368421052632, Loss: 0.00953279621899128\n",
            "Step 1000 of 1177, Accuracy: 0.99721875, Loss: 0.009511392563581467\n",
            "Step 1050 of 1177, Accuracy: 0.9971577380952381, Loss: 0.009619883261620998\n",
            "Step 1100 of 1177, Accuracy: 0.9972017045454545, Loss: 0.009529538452625275\n",
            "Step 1150 of 1177, Accuracy: 0.9972010869565218, Loss: 0.009503070265054703\n",
            "Validation\n",
            "Training accuracy:   0.9972520178419712 | Training loss: 0.009408601559698582\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0020047889556735754\n",
            "saving with loss of 0.0020047889556735754 improved over previous 0.0020047889556735754\n",
            "Epoch 3\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.008870732970535755\n",
            "Step 100 of 1177, Accuracy: 0.9975, Loss: 0.009398369118571281\n",
            "Step 150 of 1177, Accuracy: 0.9975, Loss: 0.0084700807929039\n",
            "Step 200 of 1177, Accuracy: 0.997578125, Loss: 0.007713587488979101\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.007658419664949179\n",
            "Step 300 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007533195894211531\n",
            "Step 350 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007760143838822842\n",
            "Step 400 of 1177, Accuracy: 0.997578125, Loss: 0.007772259879857302\n",
            "Step 450 of 1177, Accuracy: 0.9975694444444444, Loss: 0.008081011474132538\n",
            "Step 500 of 1177, Accuracy: 0.99765625, Loss: 0.00787175539880991\n",
            "Step 550 of 1177, Accuracy: 0.9976136363636363, Loss: 0.008068590424954891\n",
            "Step 600 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007958320900797844\n",
            "Step 650 of 1177, Accuracy: 0.9975, Loss: 0.00838444847613573\n",
            "Step 700 of 1177, Accuracy: 0.9974553571428572, Loss: 0.008511536754667759\n",
            "Step 750 of 1177, Accuracy: 0.9974583333333333, Loss: 0.008470868691802025\n",
            "Step 800 of 1177, Accuracy: 0.99748046875, Loss: 0.008428970351815224\n",
            "Step 850 of 1177, Accuracy: 0.9974448529411765, Loss: 0.008564945310354233\n",
            "Step 900 of 1177, Accuracy: 0.9974652777777778, Loss: 0.008579527959227562\n",
            "Step 950 of 1177, Accuracy: 0.9975328947368421, Loss: 0.008404300548136234\n",
            "Step 1000 of 1177, Accuracy: 0.99759375, Loss: 0.008248234167695045\n",
            "Step 1050 of 1177, Accuracy: 0.9976190476190476, Loss: 0.008140700869262218\n",
            "Step 1100 of 1177, Accuracy: 0.9976846590909091, Loss: 0.007974819280207157\n",
            "Step 1150 of 1177, Accuracy: 0.9976358695652174, Loss: 0.008049558848142624\n",
            "Validation\n",
            "Training accuracy:   0.9976502761257434 | Training loss: 0.007980823516845703\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0014327997341752052\n",
            "saving with loss of 0.0014327997341752052 improved over previous 0.0014327997341752052\n",
            "Epoch 4\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99625, Loss: 0.012751451693475246\n",
            "Step 100 of 1177, Accuracy: 0.9971875, Loss: 0.009436512365937233\n",
            "Step 150 of 1177, Accuracy: 0.9969791666666666, Loss: 0.009268571622669697\n",
            "Step 200 of 1177, Accuracy: 0.9975, Loss: 0.007805319968611002\n",
            "Step 250 of 1177, Accuracy: 0.997375, Loss: 0.008043136447668076\n",
            "Step 300 of 1177, Accuracy: 0.99734375, Loss: 0.008096159435808659\n",
            "Step 350 of 1177, Accuracy: 0.9974107142857143, Loss: 0.008348100818693638\n",
            "Step 400 of 1177, Accuracy: 0.9974609375, Loss: 0.00804220326244831\n",
            "Step 450 of 1177, Accuracy: 0.9974652777777778, Loss: 0.00826939009130001\n",
            "Step 500 of 1177, Accuracy: 0.9975625, Loss: 0.00798786524683237\n",
            "Step 550 of 1177, Accuracy: 0.9976704545454546, Loss: 0.007882015779614449\n",
            "Step 600 of 1177, Accuracy: 0.9976822916666667, Loss: 0.007894089445471764\n",
            "Step 650 of 1177, Accuracy: 0.9976682692307692, Loss: 0.007915494963526726\n",
            "Step 700 of 1177, Accuracy: 0.9975892857142857, Loss: 0.008160298690199852\n",
            "Step 750 of 1177, Accuracy: 0.997625, Loss: 0.00800673570483923\n",
            "Step 800 of 1177, Accuracy: 0.9976171875, Loss: 0.008087659254670143\n",
            "Step 850 of 1177, Accuracy: 0.9975, Loss: 0.008362113498151302\n",
            "Step 900 of 1177, Accuracy: 0.9974305555555556, Loss: 0.008665897883474827\n",
            "Step 950 of 1177, Accuracy: 0.9974013157894737, Loss: 0.00868171826004982\n",
            "Step 1000 of 1177, Accuracy: 0.997375, Loss: 0.008554300293326378\n",
            "Step 1050 of 1177, Accuracy: 0.9973809523809524, Loss: 0.008564531803131104\n",
            "Step 1100 of 1177, Accuracy: 0.9973295454545454, Loss: 0.008714623749256134\n",
            "Step 1150 of 1177, Accuracy: 0.9973505434782609, Loss: 0.008721021935343742\n",
            "Validation\n",
            "Training accuracy:   0.9973582200509771 | Training loss: 0.008706063032150269\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0014136276440694928\n",
            "saving with loss of 0.0014136276440694928 improved over previous 0.0014136276440694928\n",
            "Epoch 5\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9965625, Loss: 0.011444516479969025\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.008330758661031723\n",
            "Step 150 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007547399029135704\n",
            "Step 200 of 1177, Accuracy: 0.997734375, Loss: 0.007556062191724777\n",
            "Step 250 of 1177, Accuracy: 0.9979375, Loss: 0.00742551451548934\n",
            "Step 300 of 1177, Accuracy: 0.9979166666666667, Loss: 0.007862770929932594\n",
            "Step 350 of 1177, Accuracy: 0.9979910714285715, Loss: 0.007301597390323877\n",
            "Step 400 of 1177, Accuracy: 0.9978125, Loss: 0.007589682936668396\n",
            "Step 450 of 1177, Accuracy: 0.9979513888888889, Loss: 0.007212439551949501\n",
            "Step 500 of 1177, Accuracy: 0.9978125, Loss: 0.007756377104669809\n",
            "Step 550 of 1177, Accuracy: 0.9976136363636363, Loss: 0.007909176871180534\n",
            "Step 600 of 1177, Accuracy: 0.9975, Loss: 0.00828784704208374\n",
            "Step 650 of 1177, Accuracy: 0.9975961538461539, Loss: 0.008047258481383324\n",
            "Step 700 of 1177, Accuracy: 0.9976339285714285, Loss: 0.007954450324177742\n",
            "Step 750 of 1177, Accuracy: 0.9976875, Loss: 0.007824543863534927\n",
            "Step 800 of 1177, Accuracy: 0.99763671875, Loss: 0.007865852676331997\n",
            "Step 850 of 1177, Accuracy: 0.9975919117647059, Loss: 0.008094464428722858\n",
            "Step 900 of 1177, Accuracy: 0.9975868055555556, Loss: 0.008055553771555424\n",
            "Step 950 of 1177, Accuracy: 0.9976480263157895, Loss: 0.007896021008491516\n",
            "Step 1000 of 1177, Accuracy: 0.997609375, Loss: 0.007829304784536362\n",
            "Step 1050 of 1177, Accuracy: 0.9975892857142857, Loss: 0.008068451657891273\n",
            "Step 1100 of 1177, Accuracy: 0.997627840909091, Loss: 0.007914872840046883\n",
            "Step 1150 of 1177, Accuracy: 0.9976358695652174, Loss: 0.007782204542309046\n",
            "Validation\n",
            "Training accuracy:   0.9976635514018691 | Training loss: 0.007803492248058319\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006458006100729108\n",
            "saving with loss of 0.0006458006100729108 improved over previous 0.0006458006100729108\n",
            "Epoch 6\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9965625, Loss: 0.009927771054208279\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.00838377233594656\n",
            "Step 150 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007617963012307882\n",
            "Step 200 of 1177, Accuracy: 0.99734375, Loss: 0.008372420445084572\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.007575089577585459\n",
            "Step 300 of 1177, Accuracy: 0.9975520833333333, Loss: 0.007987967692315578\n",
            "Step 350 of 1177, Accuracy: 0.9976339285714285, Loss: 0.007988511584699154\n",
            "Step 400 of 1177, Accuracy: 0.9975390625, Loss: 0.008477079682052135\n",
            "Step 450 of 1177, Accuracy: 0.9974652777777778, Loss: 0.00846042763441801\n",
            "Step 500 of 1177, Accuracy: 0.99759375, Loss: 0.008047240786254406\n",
            "Step 550 of 1177, Accuracy: 0.9975284090909091, Loss: 0.008219088427722454\n",
            "Step 600 of 1177, Accuracy: 0.9975260416666667, Loss: 0.00820517260581255\n",
            "Step 650 of 1177, Accuracy: 0.9975480769230769, Loss: 0.00815495289862156\n",
            "Step 700 of 1177, Accuracy: 0.9977008928571428, Loss: 0.007698277942836285\n",
            "Step 750 of 1177, Accuracy: 0.9977083333333333, Loss: 0.00759525503963232\n",
            "Step 800 of 1177, Accuracy: 0.99759765625, Loss: 0.008018473163247108\n",
            "Step 850 of 1177, Accuracy: 0.997610294117647, Loss: 0.007959493435919285\n",
            "Step 900 of 1177, Accuracy: 0.9975694444444444, Loss: 0.007993781007826328\n",
            "Step 950 of 1177, Accuracy: 0.9975657894736842, Loss: 0.008140061981976032\n",
            "Step 1000 of 1177, Accuracy: 0.997578125, Loss: 0.008179936558008194\n",
            "Step 1050 of 1177, Accuracy: 0.9975892857142857, Loss: 0.008151036687195301\n",
            "Step 1100 of 1177, Accuracy: 0.9976136363636363, Loss: 0.008146671578288078\n",
            "Step 1150 of 1177, Accuracy: 0.9975815217391304, Loss: 0.008171678520739079\n",
            "Validation\n",
            "Training accuracy:   0.9975706244689889 | Training loss: 0.008107379078865051\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0008176397532224655\n",
            "Epoch 7\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.996875, Loss: 0.008962767198681831\n",
            "Step 100 of 1177, Accuracy: 0.99671875, Loss: 0.010149630717933178\n",
            "Step 150 of 1177, Accuracy: 0.9972916666666667, Loss: 0.00867814663797617\n",
            "Step 200 of 1177, Accuracy: 0.997578125, Loss: 0.00817536748945713\n",
            "Step 250 of 1177, Accuracy: 0.9975, Loss: 0.008719741366803646\n",
            "Step 300 of 1177, Accuracy: 0.9974479166666667, Loss: 0.008678775280714035\n",
            "Step 350 of 1177, Accuracy: 0.9975892857142857, Loss: 0.008079689927399158\n",
            "Step 400 of 1177, Accuracy: 0.9976171875, Loss: 0.007926041260361671\n",
            "Step 450 of 1177, Accuracy: 0.9975347222222222, Loss: 0.008438510820269585\n",
            "Step 500 of 1177, Accuracy: 0.997625, Loss: 0.008194542489945889\n",
            "Step 550 of 1177, Accuracy: 0.9976136363636363, Loss: 0.008077907375991344\n",
            "Step 600 of 1177, Accuracy: 0.9977083333333333, Loss: 0.0077586183324456215\n",
            "Step 650 of 1177, Accuracy: 0.997764423076923, Loss: 0.007440543733537197\n",
            "Step 700 of 1177, Accuracy: 0.99765625, Loss: 0.007637522649019957\n",
            "Step 750 of 1177, Accuracy: 0.9976875, Loss: 0.007554312236607075\n",
            "Step 800 of 1177, Accuracy: 0.99765625, Loss: 0.007613868918269873\n",
            "Step 850 of 1177, Accuracy: 0.997610294117647, Loss: 0.007694833911955357\n",
            "Step 900 of 1177, Accuracy: 0.9976215277777778, Loss: 0.007621447090059519\n",
            "Step 950 of 1177, Accuracy: 0.9976809210526316, Loss: 0.0074428897351026535\n",
            "Step 1000 of 1177, Accuracy: 0.997625, Loss: 0.007586223538964987\n",
            "Step 1050 of 1177, Accuracy: 0.9976190476190476, Loss: 0.007674077525734901\n",
            "Step 1100 of 1177, Accuracy: 0.9975994318181818, Loss: 0.007819452323019505\n",
            "Step 1150 of 1177, Accuracy: 0.9976358695652174, Loss: 0.007831085473299026\n",
            "Validation\n",
            "Training accuracy:   0.9976502761257434 | Training loss: 0.0077592190355062485\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006721299723722041\n",
            "Epoch 8\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.003408928168937564\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.007028308697044849\n",
            "Step 150 of 1177, Accuracy: 0.9984375, Loss: 0.005793207325041294\n",
            "Step 200 of 1177, Accuracy: 0.99828125, Loss: 0.0057372646406292915\n",
            "Step 250 of 1177, Accuracy: 0.9980625, Loss: 0.006386261899024248\n",
            "Step 300 of 1177, Accuracy: 0.9978125, Loss: 0.006718501914292574\n",
            "Step 350 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007688778918236494\n",
            "Step 400 of 1177, Accuracy: 0.9976171875, Loss: 0.007460385095328093\n",
            "Step 450 of 1177, Accuracy: 0.9974652777777778, Loss: 0.007662657648324966\n",
            "Step 500 of 1177, Accuracy: 0.9975625, Loss: 0.007461783941835165\n",
            "Step 550 of 1177, Accuracy: 0.9976136363636363, Loss: 0.0073295170441269875\n",
            "Step 600 of 1177, Accuracy: 0.9976302083333334, Loss: 0.0072368234395980835\n",
            "Step 650 of 1177, Accuracy: 0.9977163461538462, Loss: 0.007038803771138191\n",
            "Step 700 of 1177, Accuracy: 0.9976339285714285, Loss: 0.007304068189114332\n",
            "Step 750 of 1177, Accuracy: 0.997625, Loss: 0.007402359042316675\n",
            "Step 800 of 1177, Accuracy: 0.99763671875, Loss: 0.00757981464266777\n",
            "Step 850 of 1177, Accuracy: 0.9975919117647059, Loss: 0.0075128027237951756\n",
            "Step 900 of 1177, Accuracy: 0.9976388888888889, Loss: 0.00740227522328496\n",
            "Step 950 of 1177, Accuracy: 0.9976315789473684, Loss: 0.007579735014587641\n",
            "Step 1000 of 1177, Accuracy: 0.997671875, Loss: 0.0074330721981823444\n",
            "Step 1050 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007289092056453228\n",
            "Step 1100 of 1177, Accuracy: 0.9976420454545455, Loss: 0.007485751062631607\n",
            "Step 1150 of 1177, Accuracy: 0.9976358695652174, Loss: 0.00752849830314517\n",
            "Validation\n",
            "Training accuracy:   0.9976502761257434 | Training loss: 0.007509916089475155\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005867424770258367\n",
            "saving with loss of 0.0005867424770258367 improved over previous 0.0005867424770258367\n",
            "Epoch 9\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.006262054666876793\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.005934903398156166\n",
            "Step 150 of 1177, Accuracy: 0.9975, Loss: 0.007547131273895502\n",
            "Step 200 of 1177, Accuracy: 0.997265625, Loss: 0.007800087332725525\n",
            "Step 250 of 1177, Accuracy: 0.99725, Loss: 0.00825981330126524\n",
            "Step 300 of 1177, Accuracy: 0.9972916666666667, Loss: 0.008068045601248741\n",
            "Step 350 of 1177, Accuracy: 0.9973214285714286, Loss: 0.008131014183163643\n",
            "Step 400 of 1177, Accuracy: 0.997421875, Loss: 0.007828474044799805\n",
            "Step 450 of 1177, Accuracy: 0.9974305555555556, Loss: 0.007591629400849342\n",
            "Step 500 of 1177, Accuracy: 0.99715625, Loss: 0.008532026782631874\n",
            "Step 550 of 1177, Accuracy: 0.9973295454545454, Loss: 0.008147641085088253\n",
            "Step 600 of 1177, Accuracy: 0.9973697916666666, Loss: 0.007934155873954296\n",
            "Step 650 of 1177, Accuracy: 0.9974278846153846, Loss: 0.007846402935683727\n",
            "Step 700 of 1177, Accuracy: 0.9974553571428572, Loss: 0.007727745454758406\n",
            "Step 750 of 1177, Accuracy: 0.9975625, Loss: 0.007501000538468361\n",
            "Step 800 of 1177, Accuracy: 0.9976171875, Loss: 0.007364488206803799\n",
            "Step 850 of 1177, Accuracy: 0.9976286764705883, Loss: 0.007420822978019714\n",
            "Step 900 of 1177, Accuracy: 0.9975520833333333, Loss: 0.007596560753881931\n",
            "Step 950 of 1177, Accuracy: 0.9975822368421052, Loss: 0.007519913837313652\n",
            "Step 1000 of 1177, Accuracy: 0.997578125, Loss: 0.007570264860987663\n",
            "Step 1050 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007468362804502249\n",
            "Step 1100 of 1177, Accuracy: 0.9975568181818182, Loss: 0.007732905447483063\n",
            "Step 1150 of 1177, Accuracy: 0.9975135869565217, Loss: 0.007820975035429\n",
            "Validation\n",
            "Training accuracy:   0.9974909728122345 | Training loss: 0.007875273004174232\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006990777910687029\n",
            "Epoch 10\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.008663811720907688\n",
            "Step 100 of 1177, Accuracy: 0.9984375, Loss: 0.0063988808542490005\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.0076773762702941895\n",
            "Step 200 of 1177, Accuracy: 0.997890625, Loss: 0.007146663032472134\n",
            "Step 250 of 1177, Accuracy: 0.9978125, Loss: 0.007185661233961582\n",
            "Step 300 of 1177, Accuracy: 0.9977604166666667, Loss: 0.006995913106948137\n",
            "Step 350 of 1177, Accuracy: 0.9978125, Loss: 0.007214182522147894\n",
            "Step 400 of 1177, Accuracy: 0.9978125, Loss: 0.00725243054330349\n",
            "Step 450 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007574331946671009\n",
            "Step 500 of 1177, Accuracy: 0.99759375, Loss: 0.008188817650079727\n",
            "Step 550 of 1177, Accuracy: 0.9976136363636363, Loss: 0.008364462293684483\n",
            "Step 600 of 1177, Accuracy: 0.997578125, Loss: 0.00850723311305046\n",
            "Step 650 of 1177, Accuracy: 0.9976682692307692, Loss: 0.008207298815250397\n",
            "Step 700 of 1177, Accuracy: 0.99765625, Loss: 0.008209769614040852\n",
            "Step 750 of 1177, Accuracy: 0.9976041666666666, Loss: 0.008073675446212292\n",
            "Step 800 of 1177, Accuracy: 0.99765625, Loss: 0.008068335242569447\n",
            "Step 850 of 1177, Accuracy: 0.9976654411764706, Loss: 0.007873889990150928\n",
            "Step 900 of 1177, Accuracy: 0.9976388888888889, Loss: 0.007929864339530468\n",
            "Step 950 of 1177, Accuracy: 0.9976644736842105, Loss: 0.007863187231123447\n",
            "Step 1000 of 1177, Accuracy: 0.9976875, Loss: 0.007774156052619219\n",
            "Step 1050 of 1177, Accuracy: 0.9976488095238095, Loss: 0.007847860455513\n",
            "Step 1100 of 1177, Accuracy: 0.9975994318181818, Loss: 0.007894555106759071\n",
            "Step 1150 of 1177, Accuracy: 0.9976086956521739, Loss: 0.007941624149680138\n",
            "Validation\n",
            "Training accuracy:   0.9975573491928632 | Training loss: 0.00813287403434515\n",
            "Validation accuracy: 1.0 | Validation loss: 0.000969522341620177\n",
            "Epoch 11\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.006375576369464397\n",
            "Step 100 of 1177, Accuracy: 0.9984375, Loss: 0.004629106726497412\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006054916884750128\n",
            "Step 200 of 1177, Accuracy: 0.998203125, Loss: 0.005402739625424147\n",
            "Step 250 of 1177, Accuracy: 0.997625, Loss: 0.006590874399989843\n",
            "Step 300 of 1177, Accuracy: 0.9975520833333333, Loss: 0.006595850922167301\n",
            "Step 350 of 1177, Accuracy: 0.9975, Loss: 0.006937415339052677\n",
            "Step 400 of 1177, Accuracy: 0.9975390625, Loss: 0.006895463448017836\n",
            "Step 450 of 1177, Accuracy: 0.9975, Loss: 0.007179189473390579\n",
            "Step 500 of 1177, Accuracy: 0.99753125, Loss: 0.007207813672721386\n",
            "Step 550 of 1177, Accuracy: 0.9975852272727272, Loss: 0.007055922877043486\n",
            "Step 600 of 1177, Accuracy: 0.9975, Loss: 0.007304892409592867\n",
            "Step 650 of 1177, Accuracy: 0.9974519230769231, Loss: 0.007486831396818161\n",
            "Step 700 of 1177, Accuracy: 0.9975, Loss: 0.007254611235111952\n",
            "Step 750 of 1177, Accuracy: 0.9974791666666667, Loss: 0.007379909045994282\n",
            "Step 800 of 1177, Accuracy: 0.99740234375, Loss: 0.007570100482553244\n",
            "Step 850 of 1177, Accuracy: 0.9974816176470588, Loss: 0.0075295655988156796\n",
            "Step 900 of 1177, Accuracy: 0.9975, Loss: 0.007490727584809065\n",
            "Step 950 of 1177, Accuracy: 0.9975328947368421, Loss: 0.007389263715595007\n",
            "Step 1000 of 1177, Accuracy: 0.9975625, Loss: 0.00734805129468441\n",
            "Step 1050 of 1177, Accuracy: 0.997470238095238, Loss: 0.007526266388595104\n",
            "Step 1100 of 1177, Accuracy: 0.9974857954545454, Loss: 0.007433982100337744\n",
            "Step 1150 of 1177, Accuracy: 0.9974320652173913, Loss: 0.007674974389374256\n",
            "Validation\n",
            "Training accuracy:   0.9974776975361087 | Training loss: 0.007583691738545895\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006510833045467734\n",
            "Epoch 12\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.004397150129079819\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.005568214692175388\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.0061685130931437016\n",
            "Step 200 of 1177, Accuracy: 0.997734375, Loss: 0.0067542726173996925\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.007181098684668541\n",
            "Step 300 of 1177, Accuracy: 0.9977604166666667, Loss: 0.007111090701073408\n",
            "Step 350 of 1177, Accuracy: 0.9976785714285714, Loss: 0.007219613529741764\n",
            "Step 400 of 1177, Accuracy: 0.9976171875, Loss: 0.007304565515369177\n",
            "Step 450 of 1177, Accuracy: 0.9975694444444444, Loss: 0.00728719774633646\n",
            "Step 500 of 1177, Accuracy: 0.99759375, Loss: 0.007269080728292465\n",
            "Step 550 of 1177, Accuracy: 0.9975852272727272, Loss: 0.007178022060543299\n",
            "Step 600 of 1177, Accuracy: 0.99765625, Loss: 0.006923349108546972\n",
            "Step 650 of 1177, Accuracy: 0.997764423076923, Loss: 0.006875424645841122\n",
            "Step 700 of 1177, Accuracy: 0.99765625, Loss: 0.007238206919282675\n",
            "Step 750 of 1177, Accuracy: 0.9976041666666666, Loss: 0.0073103830218315125\n",
            "Step 800 of 1177, Accuracy: 0.9975390625, Loss: 0.0074218083173036575\n",
            "Step 850 of 1177, Accuracy: 0.9975551470588235, Loss: 0.007405503187328577\n",
            "Step 900 of 1177, Accuracy: 0.9975, Loss: 0.0074682277627289295\n",
            "Step 950 of 1177, Accuracy: 0.9974506578947369, Loss: 0.007864481769502163\n",
            "Step 1000 of 1177, Accuracy: 0.9975, Loss: 0.007760572247207165\n",
            "Step 1050 of 1177, Accuracy: 0.9975, Loss: 0.0078098224475979805\n",
            "Step 1100 of 1177, Accuracy: 0.9974857954545454, Loss: 0.007915753871202469\n",
            "Step 1150 of 1177, Accuracy: 0.9974864130434783, Loss: 0.007920980453491211\n",
            "Validation\n",
            "Training accuracy:   0.9974776975361087 | Training loss: 0.007982575334608555\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007854688446968794\n",
            "Epoch 13\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.0046494328416883945\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.005869995802640915\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.005916645750403404\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.005562021862715483\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.005969672929495573\n",
            "Step 300 of 1177, Accuracy: 0.9977083333333333, Loss: 0.006506762467324734\n",
            "Step 350 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007126578129827976\n",
            "Step 400 of 1177, Accuracy: 0.997421875, Loss: 0.007400899659842253\n",
            "Step 450 of 1177, Accuracy: 0.9974305555555556, Loss: 0.007612853776663542\n",
            "Step 500 of 1177, Accuracy: 0.99753125, Loss: 0.007350376807153225\n",
            "Step 550 of 1177, Accuracy: 0.9975, Loss: 0.007465706672519445\n",
            "Step 600 of 1177, Accuracy: 0.997578125, Loss: 0.007344923913478851\n",
            "Step 650 of 1177, Accuracy: 0.9974519230769231, Loss: 0.007495447527617216\n",
            "Step 700 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007205465342849493\n",
            "Step 750 of 1177, Accuracy: 0.9975208333333333, Loss: 0.007237610407173634\n",
            "Step 800 of 1177, Accuracy: 0.997578125, Loss: 0.007058923132717609\n",
            "Step 850 of 1177, Accuracy: 0.997610294117647, Loss: 0.007225253619253635\n",
            "Step 900 of 1177, Accuracy: 0.9975520833333333, Loss: 0.00741227064281702\n",
            "Step 950 of 1177, Accuracy: 0.9975822368421052, Loss: 0.0072841281071305275\n",
            "Step 1000 of 1177, Accuracy: 0.99759375, Loss: 0.007318622432649136\n",
            "Step 1050 of 1177, Accuracy: 0.9975744047619047, Loss: 0.0073533798567950726\n",
            "Step 1100 of 1177, Accuracy: 0.9975710227272727, Loss: 0.007242040708661079\n",
            "Step 1150 of 1177, Accuracy: 0.9976086956521739, Loss: 0.007162881083786488\n",
            "Validation\n",
            "Training accuracy:   0.9976237255734919 | Training loss: 0.0071279192343354225\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006050950032658875\n",
            "Epoch 14\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9971875, Loss: 0.008280107751488686\n",
            "Step 100 of 1177, Accuracy: 0.996875, Loss: 0.009979385882616043\n",
            "Step 150 of 1177, Accuracy: 0.9967708333333334, Loss: 0.010707633569836617\n",
            "Step 200 of 1177, Accuracy: 0.997109375, Loss: 0.009269313886761665\n",
            "Step 250 of 1177, Accuracy: 0.99725, Loss: 0.009118945337831974\n",
            "Step 300 of 1177, Accuracy: 0.9975, Loss: 0.008583346381783485\n",
            "Step 350 of 1177, Accuracy: 0.9975892857142857, Loss: 0.008610924705862999\n",
            "Step 400 of 1177, Accuracy: 0.99765625, Loss: 0.008392032235860825\n",
            "Step 450 of 1177, Accuracy: 0.9976041666666666, Loss: 0.008319436572492123\n",
            "Step 500 of 1177, Accuracy: 0.99746875, Loss: 0.008480163291096687\n",
            "Step 550 of 1177, Accuracy: 0.9974431818181818, Loss: 0.008607103489339352\n",
            "Step 600 of 1177, Accuracy: 0.997421875, Loss: 0.008528023958206177\n",
            "Step 650 of 1177, Accuracy: 0.9973798076923077, Loss: 0.008714502677321434\n",
            "Step 700 of 1177, Accuracy: 0.9974107142857143, Loss: 0.008563253097236156\n",
            "Step 750 of 1177, Accuracy: 0.9975416666666667, Loss: 0.008298954926431179\n",
            "Step 800 of 1177, Accuracy: 0.99751953125, Loss: 0.008204503916203976\n",
            "Step 850 of 1177, Accuracy: 0.9973713235294117, Loss: 0.008640027604997158\n",
            "Step 900 of 1177, Accuracy: 0.9973784722222222, Loss: 0.008592854253947735\n",
            "Step 950 of 1177, Accuracy: 0.9974506578947369, Loss: 0.008350959047675133\n",
            "Step 1000 of 1177, Accuracy: 0.997453125, Loss: 0.008211805485188961\n",
            "Step 1050 of 1177, Accuracy: 0.997529761904762, Loss: 0.008026506751775742\n",
            "Step 1100 of 1177, Accuracy: 0.9975284090909091, Loss: 0.007979023270308971\n",
            "Step 1150 of 1177, Accuracy: 0.9975679347826087, Loss: 0.0078659662976861\n",
            "Validation\n",
            "Training accuracy:   0.9975971750212405 | Training loss: 0.007750767283141613\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005890264874324203\n",
            "Epoch 15\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.004714089445769787\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.00857520941644907\n",
            "Step 150 of 1177, Accuracy: 0.9975, Loss: 0.008868159726262093\n",
            "Step 200 of 1177, Accuracy: 0.997734375, Loss: 0.008324205875396729\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.008450808934867382\n",
            "Step 300 of 1177, Accuracy: 0.9975, Loss: 0.009332163259387016\n",
            "Step 350 of 1177, Accuracy: 0.9973214285714286, Loss: 0.009283117949962616\n",
            "Step 400 of 1177, Accuracy: 0.99734375, Loss: 0.00878366269171238\n",
            "Step 450 of 1177, Accuracy: 0.9974652777777778, Loss: 0.008630715310573578\n",
            "Step 500 of 1177, Accuracy: 0.9975, Loss: 0.008753550238907337\n",
            "Step 550 of 1177, Accuracy: 0.9975852272727272, Loss: 0.00847061537206173\n",
            "Step 600 of 1177, Accuracy: 0.99765625, Loss: 0.0081916069611907\n",
            "Step 650 of 1177, Accuracy: 0.9976923076923077, Loss: 0.008044198155403137\n",
            "Step 700 of 1177, Accuracy: 0.9976116071428571, Loss: 0.007996844127774239\n",
            "Step 750 of 1177, Accuracy: 0.9976666666666667, Loss: 0.007903490215539932\n",
            "Step 800 of 1177, Accuracy: 0.9978125, Loss: 0.007527042645961046\n",
            "Step 850 of 1177, Accuracy: 0.9978860294117647, Loss: 0.007220128085464239\n",
            "Step 900 of 1177, Accuracy: 0.9978645833333334, Loss: 0.007212875876575708\n",
            "Step 950 of 1177, Accuracy: 0.9978453947368421, Loss: 0.00714920787140727\n",
            "Step 1000 of 1177, Accuracy: 0.997796875, Loss: 0.007150416262447834\n",
            "Step 1050 of 1177, Accuracy: 0.9977827380952381, Loss: 0.007060003932565451\n",
            "Step 1100 of 1177, Accuracy: 0.9977698863636364, Loss: 0.007191076874732971\n",
            "Step 1150 of 1177, Accuracy: 0.9977581521739131, Loss: 0.00738299498334527\n",
            "Validation\n",
            "Training accuracy:   0.9977830288870009 | Training loss: 0.00729394843801856\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007999098161235452\n",
            "Epoch 16\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.005829340778291225\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.0063374899327754974\n",
            "Step 150 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007138285785913467\n",
            "Step 200 of 1177, Accuracy: 0.99765625, Loss: 0.008117707446217537\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.007383731659501791\n",
            "Step 300 of 1177, Accuracy: 0.9977604166666667, Loss: 0.007408822420984507\n",
            "Step 350 of 1177, Accuracy: 0.9975892857142857, Loss: 0.007334569003432989\n",
            "Step 400 of 1177, Accuracy: 0.9976171875, Loss: 0.007312106899917126\n",
            "Step 450 of 1177, Accuracy: 0.9975347222222222, Loss: 0.007598130963742733\n",
            "Step 500 of 1177, Accuracy: 0.99765625, Loss: 0.007288728374987841\n",
            "Step 550 of 1177, Accuracy: 0.9976704545454546, Loss: 0.007302486337721348\n",
            "Step 600 of 1177, Accuracy: 0.9976822916666667, Loss: 0.007196336518973112\n",
            "Step 650 of 1177, Accuracy: 0.9975721153846154, Loss: 0.007724494207650423\n",
            "Step 700 of 1177, Accuracy: 0.9976116071428571, Loss: 0.007718109525740147\n",
            "Step 750 of 1177, Accuracy: 0.9976666666666667, Loss: 0.00750682782381773\n",
            "Step 800 of 1177, Accuracy: 0.9976953125, Loss: 0.007281472906470299\n",
            "Step 850 of 1177, Accuracy: 0.9977389705882352, Loss: 0.007258546072989702\n",
            "Step 900 of 1177, Accuracy: 0.9977604166666667, Loss: 0.007201128639280796\n",
            "Step 950 of 1177, Accuracy: 0.9977467105263158, Loss: 0.007257816847413778\n",
            "Step 1000 of 1177, Accuracy: 0.99771875, Loss: 0.007276229094713926\n",
            "Step 1050 of 1177, Accuracy: 0.9977678571428571, Loss: 0.007089297287166119\n",
            "Step 1100 of 1177, Accuracy: 0.99765625, Loss: 0.007411054335534573\n",
            "Step 1150 of 1177, Accuracy: 0.9976630434782608, Loss: 0.007504499051719904\n",
            "Validation\n",
            "Training accuracy:   0.9976237255734919 | Training loss: 0.007567785680294037\n",
            "Validation accuracy: 1.0 | Validation loss: 0.00067474867682904\n",
            "Epoch 17\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9984375, Loss: 0.004704607184976339\n",
            "Step 100 of 1177, Accuracy: 0.99765625, Loss: 0.006944458931684494\n",
            "Step 150 of 1177, Accuracy: 0.9977083333333333, Loss: 0.006202796008437872\n",
            "Step 200 of 1177, Accuracy: 0.9975, Loss: 0.006589880213141441\n",
            "Step 250 of 1177, Accuracy: 0.9975, Loss: 0.0067253196612000465\n",
            "Step 300 of 1177, Accuracy: 0.9975, Loss: 0.006545729469507933\n",
            "Step 350 of 1177, Accuracy: 0.9975446428571428, Loss: 0.006233587395399809\n",
            "Step 400 of 1177, Accuracy: 0.997421875, Loss: 0.006676823366433382\n",
            "Step 450 of 1177, Accuracy: 0.9972569444444445, Loss: 0.00698745995759964\n",
            "Step 500 of 1177, Accuracy: 0.99725, Loss: 0.007077714893966913\n",
            "Step 550 of 1177, Accuracy: 0.9973579545454545, Loss: 0.006852175109088421\n",
            "Step 600 of 1177, Accuracy: 0.9972916666666667, Loss: 0.007461088709533215\n",
            "Step 650 of 1177, Accuracy: 0.9973317307692308, Loss: 0.007518581114709377\n",
            "Step 700 of 1177, Accuracy: 0.9972991071428572, Loss: 0.007731316611170769\n",
            "Step 750 of 1177, Accuracy: 0.9972291666666667, Loss: 0.00789820309728384\n",
            "Step 800 of 1177, Accuracy: 0.99732421875, Loss: 0.007662779651582241\n",
            "Step 850 of 1177, Accuracy: 0.9973161764705882, Loss: 0.007730723358690739\n",
            "Step 900 of 1177, Accuracy: 0.9973784722222222, Loss: 0.00760841416195035\n",
            "Step 950 of 1177, Accuracy: 0.9973355263157895, Loss: 0.007695185486227274\n",
            "Step 1000 of 1177, Accuracy: 0.997375, Loss: 0.007565076928585768\n",
            "Step 1050 of 1177, Accuracy: 0.9974255952380953, Loss: 0.0074212090112268925\n",
            "Step 1100 of 1177, Accuracy: 0.9974573863636363, Loss: 0.0074776215478777885\n",
            "Step 1150 of 1177, Accuracy: 0.9974728260869565, Loss: 0.00753254909068346\n",
            "Validation\n",
            "Training accuracy:   0.997464422259983 | Training loss: 0.0075559779070317745\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006638527847826481\n",
            "Epoch 18\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.005069243721663952\n",
            "Step 100 of 1177, Accuracy: 0.99765625, Loss: 0.006691898684948683\n",
            "Step 150 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006121558137238026\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.006450866349041462\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.006123682949692011\n",
            "Step 300 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006329528521746397\n",
            "Step 350 of 1177, Accuracy: 0.9982142857142857, Loss: 0.006012866273522377\n",
            "Step 400 of 1177, Accuracy: 0.998046875, Loss: 0.006244387477636337\n",
            "Step 450 of 1177, Accuracy: 0.9981944444444445, Loss: 0.006050691474229097\n",
            "Step 500 of 1177, Accuracy: 0.9980625, Loss: 0.006391994655132294\n",
            "Step 550 of 1177, Accuracy: 0.9980965909090909, Loss: 0.006252846214920282\n",
            "Step 600 of 1177, Accuracy: 0.9980729166666666, Loss: 0.0062112160958349705\n",
            "Step 650 of 1177, Accuracy: 0.9981009615384615, Loss: 0.006150429602712393\n",
            "Step 700 of 1177, Accuracy: 0.9980803571428571, Loss: 0.0062374696135520935\n",
            "Step 750 of 1177, Accuracy: 0.9980625, Loss: 0.006248940713703632\n",
            "Step 800 of 1177, Accuracy: 0.998125, Loss: 0.006102295126765966\n",
            "Step 850 of 1177, Accuracy: 0.998125, Loss: 0.006204382982105017\n",
            "Step 900 of 1177, Accuracy: 0.9981423611111111, Loss: 0.0060547757893800735\n",
            "Step 950 of 1177, Accuracy: 0.998092105263158, Loss: 0.006169615313410759\n",
            "Step 1000 of 1177, Accuracy: 0.998046875, Loss: 0.006354233715683222\n",
            "Step 1050 of 1177, Accuracy: 0.9980654761904761, Loss: 0.006336313672363758\n",
            "Step 1100 of 1177, Accuracy: 0.9979971590909091, Loss: 0.006418833043426275\n",
            "Step 1150 of 1177, Accuracy: 0.9980027173913043, Loss: 0.006404439453035593\n",
            "Validation\n",
            "Training accuracy:   0.997929056924384 | Training loss: 0.006561131216585636\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005329514970071614\n",
            "saving with loss of 0.0005329514970071614 improved over previous 0.0005329514970071614\n",
            "Epoch 19\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9971875, Loss: 0.00609996635466814\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.006938501726835966\n",
            "Step 150 of 1177, Accuracy: 0.9971875, Loss: 0.008366105146706104\n",
            "Step 200 of 1177, Accuracy: 0.997578125, Loss: 0.007392414379864931\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.007205373607575893\n",
            "Step 300 of 1177, Accuracy: 0.9975520833333333, Loss: 0.00738989282399416\n",
            "Step 350 of 1177, Accuracy: 0.9976339285714285, Loss: 0.006923580076545477\n",
            "Step 400 of 1177, Accuracy: 0.99765625, Loss: 0.006955472286790609\n",
            "Step 450 of 1177, Accuracy: 0.9977430555555555, Loss: 0.0065942429937422276\n",
            "Step 500 of 1177, Accuracy: 0.99771875, Loss: 0.006663574371486902\n",
            "Step 550 of 1177, Accuracy: 0.9975852272727272, Loss: 0.006926904432475567\n",
            "Step 600 of 1177, Accuracy: 0.9976302083333334, Loss: 0.006864133756607771\n",
            "Step 650 of 1177, Accuracy: 0.9976682692307692, Loss: 0.0068181417882442474\n",
            "Step 700 of 1177, Accuracy: 0.9977008928571428, Loss: 0.006751638371497393\n",
            "Step 750 of 1177, Accuracy: 0.9977083333333333, Loss: 0.006784235127270222\n",
            "Step 800 of 1177, Accuracy: 0.99763671875, Loss: 0.006907186936587095\n",
            "Step 850 of 1177, Accuracy: 0.9977022058823529, Loss: 0.006680266000330448\n",
            "Step 900 of 1177, Accuracy: 0.9976736111111111, Loss: 0.00663286168128252\n",
            "Step 950 of 1177, Accuracy: 0.9976809210526316, Loss: 0.006582960020750761\n",
            "Step 1000 of 1177, Accuracy: 0.997640625, Loss: 0.0068281046114861965\n",
            "Step 1050 of 1177, Accuracy: 0.9976934523809524, Loss: 0.006866134237498045\n",
            "Step 1100 of 1177, Accuracy: 0.9977556818181819, Loss: 0.0068079810589551926\n",
            "Step 1150 of 1177, Accuracy: 0.9977717391304348, Loss: 0.006804727483540773\n",
            "Validation\n",
            "Training accuracy:   0.9977963041631266 | Training loss: 0.006759081035852432\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005825387197546661\n",
            "Epoch 20\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.996875, Loss: 0.007552525494247675\n",
            "Step 100 of 1177, Accuracy: 0.99703125, Loss: 0.007730736862868071\n",
            "Step 150 of 1177, Accuracy: 0.9976041666666666, Loss: 0.006598455365747213\n",
            "Step 200 of 1177, Accuracy: 0.997734375, Loss: 0.006503531709313393\n",
            "Step 250 of 1177, Accuracy: 0.9978125, Loss: 0.007021370343863964\n",
            "Step 300 of 1177, Accuracy: 0.9975, Loss: 0.007994389161467552\n",
            "Step 350 of 1177, Accuracy: 0.9975, Loss: 0.007950372993946075\n",
            "Step 400 of 1177, Accuracy: 0.9974609375, Loss: 0.007900172844529152\n",
            "Step 450 of 1177, Accuracy: 0.9974305555555556, Loss: 0.007936892099678516\n",
            "Step 500 of 1177, Accuracy: 0.9975, Loss: 0.00781729631125927\n",
            "Step 550 of 1177, Accuracy: 0.9975284090909091, Loss: 0.007872804068028927\n",
            "Step 600 of 1177, Accuracy: 0.9975520833333333, Loss: 0.007596312556415796\n",
            "Step 650 of 1177, Accuracy: 0.9974519230769231, Loss: 0.007720881141722202\n",
            "Step 700 of 1177, Accuracy: 0.9975, Loss: 0.007698581553995609\n",
            "Step 750 of 1177, Accuracy: 0.9975, Loss: 0.007860779762268066\n",
            "Step 800 of 1177, Accuracy: 0.99759765625, Loss: 0.007676212582737207\n",
            "Step 850 of 1177, Accuracy: 0.9975183823529412, Loss: 0.008085967041552067\n",
            "Step 900 of 1177, Accuracy: 0.9975694444444444, Loss: 0.008002586662769318\n",
            "Step 950 of 1177, Accuracy: 0.9975986842105263, Loss: 0.007869124412536621\n",
            "Step 1000 of 1177, Accuracy: 0.997578125, Loss: 0.007927412167191505\n",
            "Step 1050 of 1177, Accuracy: 0.9975446428571428, Loss: 0.00790998712182045\n",
            "Step 1100 of 1177, Accuracy: 0.9975710227272727, Loss: 0.007898926734924316\n",
            "Step 1150 of 1177, Accuracy: 0.9974864130434783, Loss: 0.008140787482261658\n",
            "Validation\n",
            "Training accuracy:   0.997464422259983 | Training loss: 0.008118481375277042\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0008165274048224092\n",
            "Epoch 21\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9990625, Loss: 0.003046528436243534\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.006329016759991646\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.006701450329273939\n",
            "Step 200 of 1177, Accuracy: 0.997734375, Loss: 0.007902499288320541\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.007524395827203989\n",
            "Step 300 of 1177, Accuracy: 0.9978125, Loss: 0.007244395557790995\n",
            "Step 350 of 1177, Accuracy: 0.9977678571428571, Loss: 0.007394390646368265\n",
            "Step 400 of 1177, Accuracy: 0.99765625, Loss: 0.007308481261134148\n",
            "Step 450 of 1177, Accuracy: 0.9977083333333333, Loss: 0.007118651177734137\n",
            "Step 500 of 1177, Accuracy: 0.9978125, Loss: 0.0068541583605110645\n",
            "Step 550 of 1177, Accuracy: 0.9978977272727273, Loss: 0.0066587417386472225\n",
            "Step 600 of 1177, Accuracy: 0.9977864583333333, Loss: 0.006627370603382587\n",
            "Step 650 of 1177, Accuracy: 0.9978125, Loss: 0.006630376446992159\n",
            "Step 700 of 1177, Accuracy: 0.9976785714285714, Loss: 0.0069261291064321995\n",
            "Step 750 of 1177, Accuracy: 0.9976666666666667, Loss: 0.006996123120188713\n",
            "Step 800 of 1177, Accuracy: 0.99763671875, Loss: 0.007035584654659033\n",
            "Step 850 of 1177, Accuracy: 0.9977022058823529, Loss: 0.006833782885223627\n",
            "Step 900 of 1177, Accuracy: 0.9977256944444445, Loss: 0.0068368492648005486\n",
            "Step 950 of 1177, Accuracy: 0.9976973684210526, Loss: 0.006904187146574259\n",
            "Step 1000 of 1177, Accuracy: 0.99771875, Loss: 0.0068088676780462265\n",
            "Step 1050 of 1177, Accuracy: 0.9977529761904762, Loss: 0.006754315923899412\n",
            "Step 1100 of 1177, Accuracy: 0.9978125, Loss: 0.006668827962130308\n",
            "Step 1150 of 1177, Accuracy: 0.9978260869565218, Loss: 0.006786515936255455\n",
            "Validation\n",
            "Training accuracy:   0.9978361299915038 | Training loss: 0.006738448049873114\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006020327564328909\n",
            "Epoch 22\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.004381800536066294\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.00453421613201499\n",
            "Step 150 of 1177, Accuracy: 0.9980208333333334, Loss: 0.005346211139112711\n",
            "Step 200 of 1177, Accuracy: 0.998203125, Loss: 0.005151303019374609\n",
            "Step 250 of 1177, Accuracy: 0.998, Loss: 0.005735613871365786\n",
            "Step 300 of 1177, Accuracy: 0.9980729166666666, Loss: 0.005584878847002983\n",
            "Step 350 of 1177, Accuracy: 0.998125, Loss: 0.005532828625291586\n",
            "Step 400 of 1177, Accuracy: 0.998046875, Loss: 0.00574575737118721\n",
            "Step 450 of 1177, Accuracy: 0.9978819444444444, Loss: 0.00618517491966486\n",
            "Step 500 of 1177, Accuracy: 0.99784375, Loss: 0.0061412388458848\n",
            "Step 550 of 1177, Accuracy: 0.9977556818181819, Loss: 0.006089131347835064\n",
            "Step 600 of 1177, Accuracy: 0.9977864583333333, Loss: 0.0060752760618925095\n",
            "Step 650 of 1177, Accuracy: 0.9977163461538462, Loss: 0.00633139768615365\n",
            "Step 700 of 1177, Accuracy: 0.9977455357142857, Loss: 0.006456763483583927\n",
            "Step 750 of 1177, Accuracy: 0.9977708333333334, Loss: 0.006439825054258108\n",
            "Step 800 of 1177, Accuracy: 0.99783203125, Loss: 0.006409766152501106\n",
            "Step 850 of 1177, Accuracy: 0.9978676470588236, Loss: 0.0062456210143864155\n",
            "Step 900 of 1177, Accuracy: 0.9978993055555555, Loss: 0.006213156506419182\n",
            "Step 950 of 1177, Accuracy: 0.9977796052631579, Loss: 0.006474363151937723\n",
            "Step 1000 of 1177, Accuracy: 0.9976875, Loss: 0.006710324436426163\n",
            "Step 1050 of 1177, Accuracy: 0.9977083333333333, Loss: 0.00683722086250782\n",
            "Step 1100 of 1177, Accuracy: 0.9976988636363636, Loss: 0.006984884850680828\n",
            "Step 1150 of 1177, Accuracy: 0.9976902173913044, Loss: 0.006959280930459499\n",
            "Validation\n",
            "Training accuracy:   0.9976901019541207 | Training loss: 0.006913581397384405\n",
            "Validation accuracy: 1.0 | Validation loss: 0.00064389209728688\n",
            "Epoch 23\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.0053481715731322765\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.005077729932963848\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.005748836323618889\n",
            "Step 200 of 1177, Accuracy: 0.997890625, Loss: 0.0059970347210764885\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.005886600352823734\n",
            "Step 300 of 1177, Accuracy: 0.99765625, Loss: 0.006538635119795799\n",
            "Step 350 of 1177, Accuracy: 0.9976339285714285, Loss: 0.00682273181155324\n",
            "Step 400 of 1177, Accuracy: 0.9975390625, Loss: 0.006937282159924507\n",
            "Step 450 of 1177, Accuracy: 0.9975694444444444, Loss: 0.006879567634314299\n",
            "Step 500 of 1177, Accuracy: 0.997625, Loss: 0.006797528825700283\n",
            "Step 550 of 1177, Accuracy: 0.9976420454545455, Loss: 0.0066644856706261635\n",
            "Step 600 of 1177, Accuracy: 0.9977083333333333, Loss: 0.006397542078047991\n",
            "Step 650 of 1177, Accuracy: 0.9976682692307692, Loss: 0.006777422036975622\n",
            "Step 700 of 1177, Accuracy: 0.9976339285714285, Loss: 0.006961763836443424\n",
            "Step 750 of 1177, Accuracy: 0.9976666666666667, Loss: 0.00699789309874177\n",
            "Step 800 of 1177, Accuracy: 0.9975, Loss: 0.007489338982850313\n",
            "Step 850 of 1177, Accuracy: 0.9974264705882353, Loss: 0.008047596551477909\n",
            "Step 900 of 1177, Accuracy: 0.9973611111111111, Loss: 0.008190915919840336\n",
            "Step 950 of 1177, Accuracy: 0.9973519736842106, Loss: 0.008215128444135189\n",
            "Step 1000 of 1177, Accuracy: 0.997359375, Loss: 0.008071012794971466\n",
            "Step 1050 of 1177, Accuracy: 0.9974107142857143, Loss: 0.007877771742641926\n",
            "Step 1100 of 1177, Accuracy: 0.9975, Loss: 0.007696222048252821\n",
            "Step 1150 of 1177, Accuracy: 0.9975407608695652, Loss: 0.007606452330946922\n",
            "Validation\n",
            "Training accuracy:   0.9975573491928632 | Training loss: 0.0076394579373300076\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0008208524668589234\n",
            "Epoch 24\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9965625, Loss: 0.013360141776502132\n",
            "Step 100 of 1177, Accuracy: 0.9971875, Loss: 0.010119345970451832\n",
            "Step 150 of 1177, Accuracy: 0.9973958333333334, Loss: 0.008729008957743645\n",
            "Step 200 of 1177, Accuracy: 0.997578125, Loss: 0.008154568262398243\n",
            "Step 250 of 1177, Accuracy: 0.997625, Loss: 0.00757590914145112\n",
            "Step 300 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006786723155528307\n",
            "Step 350 of 1177, Accuracy: 0.9979910714285715, Loss: 0.006595436483621597\n",
            "Step 400 of 1177, Accuracy: 0.99796875, Loss: 0.0064324731938540936\n",
            "Step 450 of 1177, Accuracy: 0.9979861111111111, Loss: 0.006367209367454052\n",
            "Step 500 of 1177, Accuracy: 0.99784375, Loss: 0.006822047755122185\n",
            "Step 550 of 1177, Accuracy: 0.9979261363636364, Loss: 0.006652267184108496\n",
            "Step 600 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006744833197444677\n",
            "Step 650 of 1177, Accuracy: 0.997764423076923, Loss: 0.007128960452973843\n",
            "Step 700 of 1177, Accuracy: 0.9977901785714286, Loss: 0.006967635825276375\n",
            "Step 750 of 1177, Accuracy: 0.9977708333333334, Loss: 0.007024540565907955\n",
            "Step 800 of 1177, Accuracy: 0.99775390625, Loss: 0.007163051515817642\n",
            "Step 850 of 1177, Accuracy: 0.9977941176470588, Loss: 0.007011265028268099\n",
            "Step 900 of 1177, Accuracy: 0.9978298611111112, Loss: 0.006859823130071163\n",
            "Step 950 of 1177, Accuracy: 0.9978782894736842, Loss: 0.006874586455523968\n",
            "Step 1000 of 1177, Accuracy: 0.997921875, Loss: 0.006711732596158981\n",
            "Step 1050 of 1177, Accuracy: 0.9979017857142857, Loss: 0.006715427618473768\n",
            "Step 1100 of 1177, Accuracy: 0.9978977272727273, Loss: 0.006794529967010021\n",
            "Step 1150 of 1177, Accuracy: 0.9979076086956522, Loss: 0.006786920130252838\n",
            "Validation\n",
            "Training accuracy:   0.9978892310960068 | Training loss: 0.006815391592681408\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007362669566646218\n",
            "Epoch 25\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.996875, Loss: 0.008640247397124767\n",
            "Step 100 of 1177, Accuracy: 0.998125, Loss: 0.006110758055001497\n",
            "Step 150 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006238879635930061\n",
            "Step 200 of 1177, Accuracy: 0.99765625, Loss: 0.006857150234282017\n",
            "Step 250 of 1177, Accuracy: 0.99775, Loss: 0.006502566859126091\n",
            "Step 300 of 1177, Accuracy: 0.9977083333333333, Loss: 0.0062912842258811\n",
            "Step 350 of 1177, Accuracy: 0.9976785714285714, Loss: 0.0063812448643147945\n",
            "Step 400 of 1177, Accuracy: 0.9975390625, Loss: 0.006963291671127081\n",
            "Step 450 of 1177, Accuracy: 0.9975, Loss: 0.007079204544425011\n",
            "Step 500 of 1177, Accuracy: 0.99765625, Loss: 0.006770391017198563\n",
            "Step 550 of 1177, Accuracy: 0.9976988636363636, Loss: 0.006884320639073849\n",
            "Step 600 of 1177, Accuracy: 0.9976302083333334, Loss: 0.00748138502240181\n",
            "Step 650 of 1177, Accuracy: 0.9975480769230769, Loss: 0.007489764131605625\n",
            "Step 700 of 1177, Accuracy: 0.9975446428571428, Loss: 0.0074223619885742664\n",
            "Step 750 of 1177, Accuracy: 0.9975625, Loss: 0.007297525182366371\n",
            "Step 800 of 1177, Accuracy: 0.9975390625, Loss: 0.007289526984095573\n",
            "Step 850 of 1177, Accuracy: 0.9975551470588235, Loss: 0.0072213634848594666\n",
            "Step 900 of 1177, Accuracy: 0.9975173611111111, Loss: 0.007106758188456297\n",
            "Step 950 of 1177, Accuracy: 0.9975, Loss: 0.0072160204872488976\n",
            "Step 1000 of 1177, Accuracy: 0.997546875, Loss: 0.007052149623632431\n",
            "Step 1050 of 1177, Accuracy: 0.9975446428571428, Loss: 0.0071081118658185005\n",
            "Step 1100 of 1177, Accuracy: 0.9975284090909091, Loss: 0.007305962033569813\n",
            "Step 1150 of 1177, Accuracy: 0.9974864130434783, Loss: 0.007318540010601282\n",
            "Validation\n",
            "Training accuracy:   0.997464422259983 | Training loss: 0.007365875877439976\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006977368029765785\n",
            "Epoch 26\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.005721156485378742\n",
            "Step 100 of 1177, Accuracy: 0.9984375, Loss: 0.004453783854842186\n",
            "Step 150 of 1177, Accuracy: 0.9982291666666666, Loss: 0.005901847034692764\n",
            "Step 200 of 1177, Accuracy: 0.998125, Loss: 0.005530654918402433\n",
            "Step 250 of 1177, Accuracy: 0.9980625, Loss: 0.006146024446934462\n",
            "Step 300 of 1177, Accuracy: 0.9980729166666666, Loss: 0.00608355225995183\n",
            "Step 350 of 1177, Accuracy: 0.998125, Loss: 0.005859195254743099\n",
            "Step 400 of 1177, Accuracy: 0.998125, Loss: 0.006134430877864361\n",
            "Step 450 of 1177, Accuracy: 0.998125, Loss: 0.006334587931632996\n",
            "Step 500 of 1177, Accuracy: 0.99815625, Loss: 0.006379253230988979\n",
            "Step 550 of 1177, Accuracy: 0.9978977272727273, Loss: 0.0068291062489151955\n",
            "Step 600 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006712432485073805\n",
            "Step 650 of 1177, Accuracy: 0.9978846153846154, Loss: 0.0068510486744344234\n",
            "Step 700 of 1177, Accuracy: 0.9977901785714286, Loss: 0.007007391192018986\n",
            "Step 750 of 1177, Accuracy: 0.9977291666666667, Loss: 0.007010128814727068\n",
            "Step 800 of 1177, Accuracy: 0.99775390625, Loss: 0.0069412426091730595\n",
            "Step 850 of 1177, Accuracy: 0.9977022058823529, Loss: 0.007088805548846722\n",
            "Step 900 of 1177, Accuracy: 0.9977256944444445, Loss: 0.00693949731066823\n",
            "Step 950 of 1177, Accuracy: 0.9977631578947368, Loss: 0.006894452031701803\n",
            "Step 1000 of 1177, Accuracy: 0.99778125, Loss: 0.006832861807197332\n",
            "Step 1050 of 1177, Accuracy: 0.9977232142857143, Loss: 0.006817602086812258\n",
            "Step 1100 of 1177, Accuracy: 0.9976988636363636, Loss: 0.006891429424285889\n",
            "Step 1150 of 1177, Accuracy: 0.9976902173913044, Loss: 0.006988152861595154\n",
            "Validation\n",
            "Training accuracy:   0.9977166525063721 | Training loss: 0.006895045749843121\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005229660891927779\n",
            "saving with loss of 0.0005229660891927779 improved over previous 0.0005229660891927779\n",
            "Epoch 27\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.00382779398933053\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.00445886654779315\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.005692234728485346\n",
            "Step 200 of 1177, Accuracy: 0.998125, Loss: 0.005394722800701857\n",
            "Step 250 of 1177, Accuracy: 0.99825, Loss: 0.006258794106543064\n",
            "Step 300 of 1177, Accuracy: 0.9984375, Loss: 0.005738120060414076\n",
            "Step 350 of 1177, Accuracy: 0.9984821428571429, Loss: 0.005368991754949093\n",
            "Step 400 of 1177, Accuracy: 0.9984765625, Loss: 0.005312526598572731\n",
            "Step 450 of 1177, Accuracy: 0.9981944444444445, Loss: 0.006144095212221146\n",
            "Step 500 of 1177, Accuracy: 0.9980625, Loss: 0.006186099257320166\n",
            "Step 550 of 1177, Accuracy: 0.9979545454545454, Loss: 0.006650732830166817\n",
            "Step 600 of 1177, Accuracy: 0.9979427083333333, Loss: 0.006526181474328041\n",
            "Step 650 of 1177, Accuracy: 0.9979326923076923, Loss: 0.006561095826327801\n",
            "Step 700 of 1177, Accuracy: 0.9979017857142857, Loss: 0.006573924794793129\n",
            "Step 750 of 1177, Accuracy: 0.9979583333333333, Loss: 0.006657234858721495\n",
            "Step 800 of 1177, Accuracy: 0.9979296875, Loss: 0.006624607369303703\n",
            "Step 850 of 1177, Accuracy: 0.9979411764705882, Loss: 0.006711710710078478\n",
            "Step 900 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006768899504095316\n",
            "Step 950 of 1177, Accuracy: 0.9978618421052632, Loss: 0.006939171813428402\n",
            "Step 1000 of 1177, Accuracy: 0.997859375, Loss: 0.006978212855756283\n",
            "Step 1050 of 1177, Accuracy: 0.9978720238095238, Loss: 0.006884651258587837\n",
            "Step 1100 of 1177, Accuracy: 0.9977982954545455, Loss: 0.006947790738195181\n",
            "Step 1150 of 1177, Accuracy: 0.9977309782608695, Loss: 0.007163011934608221\n",
            "Validation\n",
            "Training accuracy:   0.997769753610875 | Training loss: 0.0070913867093622684\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007152796606533229\n",
            "Epoch 28\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.0066587058827281\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.005703415721654892\n",
            "Step 150 of 1177, Accuracy: 0.9983333333333333, Loss: 0.005522357299923897\n",
            "Step 200 of 1177, Accuracy: 0.99828125, Loss: 0.005403056740760803\n",
            "Step 250 of 1177, Accuracy: 0.99825, Loss: 0.00549314497038722\n",
            "Step 300 of 1177, Accuracy: 0.99828125, Loss: 0.005245858337730169\n",
            "Step 350 of 1177, Accuracy: 0.9983035714285714, Loss: 0.005422989372164011\n",
            "Step 400 of 1177, Accuracy: 0.9981640625, Loss: 0.005914988927543163\n",
            "Step 450 of 1177, Accuracy: 0.9980555555555556, Loss: 0.006341191008687019\n",
            "Step 500 of 1177, Accuracy: 0.99809375, Loss: 0.0063265119679272175\n",
            "Step 550 of 1177, Accuracy: 0.9980965909090909, Loss: 0.006340199615806341\n",
            "Step 600 of 1177, Accuracy: 0.9979947916666667, Loss: 0.006505080033093691\n",
            "Step 650 of 1177, Accuracy: 0.9980288461538461, Loss: 0.00647553289309144\n",
            "Step 700 of 1177, Accuracy: 0.9980357142857142, Loss: 0.006442241836339235\n",
            "Step 750 of 1177, Accuracy: 0.9980625, Loss: 0.006499565672129393\n",
            "Step 800 of 1177, Accuracy: 0.99802734375, Loss: 0.006760725285857916\n",
            "Step 850 of 1177, Accuracy: 0.9979595588235294, Loss: 0.006883698981255293\n",
            "Step 900 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006940276362001896\n",
            "Step 950 of 1177, Accuracy: 0.9979276315789474, Loss: 0.0069819907657802105\n",
            "Step 1000 of 1177, Accuracy: 0.997765625, Loss: 0.007349725812673569\n",
            "Step 1050 of 1177, Accuracy: 0.9977380952380952, Loss: 0.007422437891364098\n",
            "Step 1100 of 1177, Accuracy: 0.9976846590909091, Loss: 0.00749937491491437\n",
            "Step 1150 of 1177, Accuracy: 0.9977038043478261, Loss: 0.007418130990117788\n",
            "Validation\n",
            "Training accuracy:   0.9977166525063721 | Training loss: 0.007368767634034157\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007588387234136462\n",
            "Epoch 29\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.005988331511616707\n",
            "Step 100 of 1177, Accuracy: 0.9984375, Loss: 0.004873239900916815\n",
            "Step 150 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007985967211425304\n",
            "Step 200 of 1177, Accuracy: 0.9978125, Loss: 0.007152096834033728\n",
            "Step 250 of 1177, Accuracy: 0.99775, Loss: 0.006770051084458828\n",
            "Step 300 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007444669492542744\n",
            "Step 350 of 1177, Accuracy: 0.9976339285714285, Loss: 0.007348444312810898\n",
            "Step 400 of 1177, Accuracy: 0.9976171875, Loss: 0.007505929097533226\n",
            "Step 450 of 1177, Accuracy: 0.9975347222222222, Loss: 0.008447544649243355\n",
            "Step 500 of 1177, Accuracy: 0.9975, Loss: 0.008438531309366226\n",
            "Step 550 of 1177, Accuracy: 0.9975284090909091, Loss: 0.008133716881275177\n",
            "Step 600 of 1177, Accuracy: 0.9975, Loss: 0.008182642981410027\n",
            "Step 650 of 1177, Accuracy: 0.9975, Loss: 0.008198875933885574\n",
            "Step 700 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007976650260388851\n",
            "Step 750 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007705500815063715\n",
            "Step 800 of 1177, Accuracy: 0.99767578125, Loss: 0.007440734654664993\n",
            "Step 850 of 1177, Accuracy: 0.9976470588235294, Loss: 0.007417396176606417\n",
            "Step 900 of 1177, Accuracy: 0.99765625, Loss: 0.007283640094101429\n",
            "Step 950 of 1177, Accuracy: 0.9975822368421052, Loss: 0.007417791057378054\n",
            "Step 1000 of 1177, Accuracy: 0.997625, Loss: 0.007295725867152214\n",
            "Step 1050 of 1177, Accuracy: 0.9976488095238095, Loss: 0.007300400175154209\n",
            "Step 1100 of 1177, Accuracy: 0.9976704545454546, Loss: 0.007397469598799944\n",
            "Step 1150 of 1177, Accuracy: 0.9976902173913044, Loss: 0.007268927991390228\n",
            "Validation\n",
            "Training accuracy:   0.9976901019541207 | Training loss: 0.007277432829141617\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005656725843437016\n",
            "Epoch 30\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.006782535929232836\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.005670917686074972\n",
            "Step 150 of 1177, Accuracy: 0.9980208333333334, Loss: 0.005475878249853849\n",
            "Step 200 of 1177, Accuracy: 0.998046875, Loss: 0.005497475154697895\n",
            "Step 250 of 1177, Accuracy: 0.9979375, Loss: 0.006077133119106293\n",
            "Step 300 of 1177, Accuracy: 0.9979166666666667, Loss: 0.005774277728050947\n",
            "Step 350 of 1177, Accuracy: 0.9979464285714286, Loss: 0.005903103854507208\n",
            "Step 400 of 1177, Accuracy: 0.99796875, Loss: 0.005662392824888229\n",
            "Step 450 of 1177, Accuracy: 0.9976736111111111, Loss: 0.006626329850405455\n",
            "Step 500 of 1177, Accuracy: 0.9975625, Loss: 0.006997767370194197\n",
            "Step 550 of 1177, Accuracy: 0.9975, Loss: 0.006948381662368774\n",
            "Step 600 of 1177, Accuracy: 0.9975520833333333, Loss: 0.006924310699105263\n",
            "Step 650 of 1177, Accuracy: 0.9975240384615385, Loss: 0.006933187134563923\n",
            "Step 700 of 1177, Accuracy: 0.9975223214285714, Loss: 0.006917975842952728\n",
            "Step 750 of 1177, Accuracy: 0.9975208333333333, Loss: 0.0069989897310733795\n",
            "Step 800 of 1177, Accuracy: 0.99748046875, Loss: 0.007260288577526808\n",
            "Step 850 of 1177, Accuracy: 0.9973713235294117, Loss: 0.007703335024416447\n",
            "Step 900 of 1177, Accuracy: 0.9973958333333334, Loss: 0.007634810172021389\n",
            "Step 950 of 1177, Accuracy: 0.9975, Loss: 0.007392288185656071\n",
            "Step 1000 of 1177, Accuracy: 0.997578125, Loss: 0.007219408173114061\n",
            "Step 1050 of 1177, Accuracy: 0.9976041666666666, Loss: 0.0071293204091489315\n",
            "Step 1100 of 1177, Accuracy: 0.9976704545454546, Loss: 0.0069179898127913475\n",
            "Step 1150 of 1177, Accuracy: 0.9977173913043478, Loss: 0.006757387891411781\n",
            "Validation\n",
            "Training accuracy:   0.9976750566411782 | Training loss: 0.006742736790329218\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0004891144344583154\n",
            "saving with loss of 0.0004891144344583154 improved over previous 0.0004891144344583154\n",
            "Epoch 31\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.996875, Loss: 0.008827542886137962\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.008627059869468212\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.007166668772697449\n",
            "Step 200 of 1177, Accuracy: 0.997890625, Loss: 0.0068571800366044044\n",
            "Step 250 of 1177, Accuracy: 0.9979375, Loss: 0.006553700193762779\n",
            "Step 300 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006602578330785036\n",
            "Step 350 of 1177, Accuracy: 0.9978571428571429, Loss: 0.00677843252196908\n",
            "Step 400 of 1177, Accuracy: 0.9980078125, Loss: 0.006461541634052992\n",
            "Step 450 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006378015968948603\n",
            "Step 500 of 1177, Accuracy: 0.99803125, Loss: 0.006637508049607277\n",
            "Step 550 of 1177, Accuracy: 0.9980397727272727, Loss: 0.006470399908721447\n",
            "Step 600 of 1177, Accuracy: 0.9979947916666667, Loss: 0.006707560271024704\n",
            "Step 650 of 1177, Accuracy: 0.9979326923076923, Loss: 0.006756348069757223\n",
            "Step 700 of 1177, Accuracy: 0.9979464285714286, Loss: 0.006755625829100609\n",
            "Step 750 of 1177, Accuracy: 0.9978541666666667, Loss: 0.0070531414821743965\n",
            "Step 800 of 1177, Accuracy: 0.9978125, Loss: 0.007177026476711035\n",
            "Step 850 of 1177, Accuracy: 0.9978676470588236, Loss: 0.007148313336074352\n",
            "Step 900 of 1177, Accuracy: 0.9979340277777777, Loss: 0.006921455264091492\n",
            "Step 950 of 1177, Accuracy: 0.9978618421052632, Loss: 0.007140017114579678\n",
            "Step 1000 of 1177, Accuracy: 0.99778125, Loss: 0.007291362155228853\n",
            "Step 1050 of 1177, Accuracy: 0.9977976190476191, Loss: 0.007268962915986776\n",
            "Step 1100 of 1177, Accuracy: 0.9977556818181819, Loss: 0.00733947241678834\n",
            "Step 1150 of 1177, Accuracy: 0.9977309782608695, Loss: 0.0075285108759999275\n",
            "Validation\n",
            "Training accuracy:   0.9977148824695554 | Training loss: 0.007511142175644636\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007436385494656861\n",
            "Epoch 32\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.005009429529309273\n",
            "Step 100 of 1177, Accuracy: 0.9990625, Loss: 0.004145150538533926\n",
            "Step 150 of 1177, Accuracy: 0.9986458333333333, Loss: 0.006367737427353859\n",
            "Step 200 of 1177, Accuracy: 0.998515625, Loss: 0.0065696160309016705\n",
            "Step 250 of 1177, Accuracy: 0.9985, Loss: 0.006203311029821634\n",
            "Step 300 of 1177, Accuracy: 0.9984375, Loss: 0.006344977300614119\n",
            "Step 350 of 1177, Accuracy: 0.9982142857142857, Loss: 0.006480537820607424\n",
            "Step 400 of 1177, Accuracy: 0.9979296875, Loss: 0.007278890814632177\n",
            "Step 450 of 1177, Accuracy: 0.9978819444444444, Loss: 0.007539184298366308\n",
            "Step 500 of 1177, Accuracy: 0.99784375, Loss: 0.007528505753725767\n",
            "Step 550 of 1177, Accuracy: 0.9979545454545454, Loss: 0.00721526425331831\n",
            "Step 600 of 1177, Accuracy: 0.998046875, Loss: 0.006863697431981564\n",
            "Step 650 of 1177, Accuracy: 0.9980769230769231, Loss: 0.006927154958248138\n",
            "Step 700 of 1177, Accuracy: 0.99796875, Loss: 0.0073046209290623665\n",
            "Step 750 of 1177, Accuracy: 0.9980416666666667, Loss: 0.007128146477043629\n",
            "Step 800 of 1177, Accuracy: 0.9980078125, Loss: 0.007018174510449171\n",
            "Step 850 of 1177, Accuracy: 0.998014705882353, Loss: 0.00695525947958231\n",
            "Step 900 of 1177, Accuracy: 0.99796875, Loss: 0.006922375410795212\n",
            "Step 950 of 1177, Accuracy: 0.9978125, Loss: 0.007291084621101618\n",
            "Step 1000 of 1177, Accuracy: 0.99775, Loss: 0.007431309204548597\n",
            "Step 1050 of 1177, Accuracy: 0.9977380952380952, Loss: 0.00748616736382246\n",
            "Step 1100 of 1177, Accuracy: 0.9977414772727272, Loss: 0.0073923892341554165\n",
            "Step 1150 of 1177, Accuracy: 0.9977309782608695, Loss: 0.007376751396805048\n",
            "Validation\n",
            "Training accuracy:   0.9977033772302464 | Training loss: 0.0075110942125320435\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0008112327195703983\n",
            "Epoch 33\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9984375, Loss: 0.0049450877122581005\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.006774033885449171\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.006309728138148785\n",
            "Step 200 of 1177, Accuracy: 0.998125, Loss: 0.00621669040992856\n",
            "Step 250 of 1177, Accuracy: 0.9981875, Loss: 0.005911851767450571\n",
            "Step 300 of 1177, Accuracy: 0.9980729166666666, Loss: 0.006118350196629763\n",
            "Step 350 of 1177, Accuracy: 0.9978125, Loss: 0.007140079978853464\n",
            "Step 400 of 1177, Accuracy: 0.9979296875, Loss: 0.00700656371191144\n",
            "Step 450 of 1177, Accuracy: 0.9978125, Loss: 0.007145746145397425\n",
            "Step 500 of 1177, Accuracy: 0.99771875, Loss: 0.007829271256923676\n",
            "Step 550 of 1177, Accuracy: 0.9977840909090909, Loss: 0.007836026139557362\n",
            "Step 600 of 1177, Accuracy: 0.997890625, Loss: 0.007501041982322931\n",
            "Step 650 of 1177, Accuracy: 0.9978365384615384, Loss: 0.00737859308719635\n",
            "Step 700 of 1177, Accuracy: 0.99796875, Loss: 0.007026218809187412\n",
            "Step 750 of 1177, Accuracy: 0.998, Loss: 0.007047103717923164\n",
            "Step 800 of 1177, Accuracy: 0.99794921875, Loss: 0.006911901757121086\n",
            "Step 850 of 1177, Accuracy: 0.9979227941176471, Loss: 0.007111488841474056\n",
            "Step 900 of 1177, Accuracy: 0.9979513888888889, Loss: 0.0071302661672234535\n",
            "Step 950 of 1177, Accuracy: 0.9979111842105263, Loss: 0.007106253877282143\n",
            "Step 1000 of 1177, Accuracy: 0.9979375, Loss: 0.007057967130094767\n",
            "Step 1050 of 1177, Accuracy: 0.9979910714285715, Loss: 0.006878863088786602\n",
            "Step 1100 of 1177, Accuracy: 0.9980397727272727, Loss: 0.0066826362162828445\n",
            "Step 1150 of 1177, Accuracy: 0.9979755434782609, Loss: 0.006740885321050882\n",
            "Validation\n",
            "Training accuracy:   0.997982158028887 | Training loss: 0.006738491356372833\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005875688511878252\n",
            "Epoch 34\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9975, Loss: 0.008771445602178574\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.007467253133654594\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.007167610339820385\n",
            "Step 200 of 1177, Accuracy: 0.99828125, Loss: 0.0060972170904278755\n",
            "Step 250 of 1177, Accuracy: 0.998125, Loss: 0.0060870107263326645\n",
            "Step 300 of 1177, Accuracy: 0.9981770833333333, Loss: 0.005989106837660074\n",
            "Step 350 of 1177, Accuracy: 0.9982142857142857, Loss: 0.0055945939384400845\n",
            "Step 400 of 1177, Accuracy: 0.9980859375, Loss: 0.0058977375738322735\n",
            "Step 450 of 1177, Accuracy: 0.9980902777777778, Loss: 0.00571599043905735\n",
            "Step 500 of 1177, Accuracy: 0.99803125, Loss: 0.006110774353146553\n",
            "Step 550 of 1177, Accuracy: 0.9979261363636364, Loss: 0.006594860926270485\n",
            "Step 600 of 1177, Accuracy: 0.9978125, Loss: 0.006876018829643726\n",
            "Step 650 of 1177, Accuracy: 0.9978365384615384, Loss: 0.006884622387588024\n",
            "Step 700 of 1177, Accuracy: 0.9978794642857143, Loss: 0.0068649426102638245\n",
            "Step 750 of 1177, Accuracy: 0.9978333333333333, Loss: 0.006891412660479546\n",
            "Step 800 of 1177, Accuracy: 0.997890625, Loss: 0.006761038675904274\n",
            "Step 850 of 1177, Accuracy: 0.9978308823529412, Loss: 0.006840437185019255\n",
            "Step 900 of 1177, Accuracy: 0.9977777777777778, Loss: 0.006900619249790907\n",
            "Step 950 of 1177, Accuracy: 0.9978125, Loss: 0.006751851178705692\n",
            "Step 1000 of 1177, Accuracy: 0.99784375, Loss: 0.006582916248589754\n",
            "Step 1050 of 1177, Accuracy: 0.997827380952381, Loss: 0.0066639636643230915\n",
            "Step 1100 of 1177, Accuracy: 0.9977982954545455, Loss: 0.006591482553631067\n",
            "Step 1150 of 1177, Accuracy: 0.9977853260869565, Loss: 0.006583533715456724\n",
            "Validation\n",
            "Training accuracy:   0.9978095794392523 | Training loss: 0.006514992564916611\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005369422724470496\n",
            "Epoch 35\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9965625, Loss: 0.00842385645955801\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.006812655366957188\n",
            "Step 150 of 1177, Accuracy: 0.9973958333333334, Loss: 0.007540538441389799\n",
            "Step 200 of 1177, Accuracy: 0.99765625, Loss: 0.0068053388968110085\n",
            "Step 250 of 1177, Accuracy: 0.99775, Loss: 0.006751038134098053\n",
            "Step 300 of 1177, Accuracy: 0.9976041666666666, Loss: 0.007057248614728451\n",
            "Step 350 of 1177, Accuracy: 0.9976339285714285, Loss: 0.007204042747616768\n",
            "Step 400 of 1177, Accuracy: 0.9975390625, Loss: 0.007299158722162247\n",
            "Step 450 of 1177, Accuracy: 0.9975, Loss: 0.007248382084071636\n",
            "Step 500 of 1177, Accuracy: 0.99759375, Loss: 0.007129918783903122\n",
            "Step 550 of 1177, Accuracy: 0.9975568181818182, Loss: 0.007369752507656813\n",
            "Step 600 of 1177, Accuracy: 0.9975520833333333, Loss: 0.007359202019870281\n",
            "Step 650 of 1177, Accuracy: 0.9975, Loss: 0.0073912860825657845\n",
            "Step 700 of 1177, Accuracy: 0.9975, Loss: 0.00744202733039856\n",
            "Step 750 of 1177, Accuracy: 0.9975, Loss: 0.007418157998472452\n",
            "Step 800 of 1177, Accuracy: 0.99748046875, Loss: 0.0074411798268556595\n",
            "Step 850 of 1177, Accuracy: 0.9974816176470588, Loss: 0.007442787755280733\n",
            "Step 900 of 1177, Accuracy: 0.9975347222222222, Loss: 0.0072843339294195175\n",
            "Step 950 of 1177, Accuracy: 0.9975328947368421, Loss: 0.007187831215560436\n",
            "Step 1000 of 1177, Accuracy: 0.997546875, Loss: 0.007187278009951115\n",
            "Step 1050 of 1177, Accuracy: 0.9975892857142857, Loss: 0.007114102598279715\n",
            "Step 1100 of 1177, Accuracy: 0.9975852272727272, Loss: 0.0071779703721404076\n",
            "Step 1150 of 1177, Accuracy: 0.9976494565217391, Loss: 0.007127497345209122\n",
            "Validation\n",
            "Training accuracy:   0.9976502761257434 | Training loss: 0.007116546854376793\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005225607892498374\n",
            "Epoch 36\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.007006174884736538\n",
            "Step 100 of 1177, Accuracy: 0.9984375, Loss: 0.005329445470124483\n",
            "Step 150 of 1177, Accuracy: 0.9984375, Loss: 0.0054861693643033504\n",
            "Step 200 of 1177, Accuracy: 0.9984375, Loss: 0.0056664347648620605\n",
            "Step 250 of 1177, Accuracy: 0.9983125, Loss: 0.005653695669025183\n",
            "Step 300 of 1177, Accuracy: 0.9983854166666667, Loss: 0.0056409575045108795\n",
            "Step 350 of 1177, Accuracy: 0.9982142857142857, Loss: 0.0062460280023515224\n",
            "Step 400 of 1177, Accuracy: 0.9982421875, Loss: 0.006191561929881573\n",
            "Step 450 of 1177, Accuracy: 0.9982986111111111, Loss: 0.005957729648798704\n",
            "Step 500 of 1177, Accuracy: 0.99821875, Loss: 0.00594366854056716\n",
            "Step 550 of 1177, Accuracy: 0.9982102272727272, Loss: 0.0059457928873598576\n",
            "Step 600 of 1177, Accuracy: 0.9980989583333333, Loss: 0.006111837923526764\n",
            "Step 650 of 1177, Accuracy: 0.9982211538461538, Loss: 0.005847617518156767\n",
            "Step 700 of 1177, Accuracy: 0.9981473214285714, Loss: 0.006225596647709608\n",
            "Step 750 of 1177, Accuracy: 0.9982083333333334, Loss: 0.006008883938193321\n",
            "Step 800 of 1177, Accuracy: 0.99814453125, Loss: 0.006251039449125528\n",
            "Step 850 of 1177, Accuracy: 0.9980330882352941, Loss: 0.006490001454949379\n",
            "Step 900 of 1177, Accuracy: 0.9979861111111111, Loss: 0.006727126892656088\n",
            "Step 950 of 1177, Accuracy: 0.9979769736842106, Loss: 0.0067910258658230305\n",
            "Step 1000 of 1177, Accuracy: 0.997890625, Loss: 0.00718082208186388\n",
            "Step 1050 of 1177, Accuracy: 0.997827380952381, Loss: 0.0072283148765563965\n",
            "Step 1100 of 1177, Accuracy: 0.9977414772727272, Loss: 0.007309112697839737\n",
            "Step 1150 of 1177, Accuracy: 0.9977173913043478, Loss: 0.007313170935958624\n",
            "Validation\n",
            "Training accuracy:   0.9977432030586236 | Training loss: 0.007246518041938543\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0009395101224072278\n",
            "Epoch 37\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9971875, Loss: 0.007132032420486212\n",
            "Step 100 of 1177, Accuracy: 0.99765625, Loss: 0.00685087637975812\n",
            "Step 150 of 1177, Accuracy: 0.9978125, Loss: 0.0060180057771503925\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.006264310330152512\n",
            "Step 250 of 1177, Accuracy: 0.99775, Loss: 0.006225795950740576\n",
            "Step 300 of 1177, Accuracy: 0.9978125, Loss: 0.005962422117590904\n",
            "Step 350 of 1177, Accuracy: 0.9979464285714286, Loss: 0.005967563949525356\n",
            "Step 400 of 1177, Accuracy: 0.9978515625, Loss: 0.006202787160873413\n",
            "Step 450 of 1177, Accuracy: 0.9979861111111111, Loss: 0.00600049551576376\n",
            "Step 500 of 1177, Accuracy: 0.997875, Loss: 0.006305920425802469\n",
            "Step 550 of 1177, Accuracy: 0.9978409090909091, Loss: 0.006502725183963776\n",
            "Step 600 of 1177, Accuracy: 0.9978125, Loss: 0.00636244285851717\n",
            "Step 650 of 1177, Accuracy: 0.9978846153846154, Loss: 0.006271012593060732\n",
            "Step 700 of 1177, Accuracy: 0.9979241071428572, Loss: 0.006224252749234438\n",
            "Step 750 of 1177, Accuracy: 0.9978333333333333, Loss: 0.006520399823784828\n",
            "Step 800 of 1177, Accuracy: 0.997890625, Loss: 0.0066184294410049915\n",
            "Step 850 of 1177, Accuracy: 0.9979044117647059, Loss: 0.006610155571252108\n",
            "Step 900 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006673573981970549\n",
            "Step 950 of 1177, Accuracy: 0.9978782894736842, Loss: 0.006695772986859083\n",
            "Step 1000 of 1177, Accuracy: 0.997890625, Loss: 0.006694519426673651\n",
            "Step 1050 of 1177, Accuracy: 0.9979464285714286, Loss: 0.006577183958142996\n",
            "Step 1100 of 1177, Accuracy: 0.9979403409090909, Loss: 0.0065625314600765705\n",
            "Step 1150 of 1177, Accuracy: 0.9979483695652174, Loss: 0.006433499976992607\n",
            "Validation\n",
            "Training accuracy:   0.9979157816482583 | Training loss: 0.006556447595357895\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005623918259516358\n",
            "Epoch 38\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.00363282416947186\n",
            "Step 100 of 1177, Accuracy: 0.998125, Loss: 0.004993738606572151\n",
            "Step 150 of 1177, Accuracy: 0.9977083333333333, Loss: 0.00520969508215785\n",
            "Step 200 of 1177, Accuracy: 0.9975, Loss: 0.00612566526979208\n",
            "Step 250 of 1177, Accuracy: 0.997625, Loss: 0.0057907369919121265\n",
            "Step 300 of 1177, Accuracy: 0.9978125, Loss: 0.005497106350958347\n",
            "Step 350 of 1177, Accuracy: 0.9978571428571429, Loss: 0.005607577506452799\n",
            "Step 400 of 1177, Accuracy: 0.99765625, Loss: 0.00591683853417635\n",
            "Step 450 of 1177, Accuracy: 0.9977430555555555, Loss: 0.005604257807135582\n",
            "Step 500 of 1177, Accuracy: 0.997625, Loss: 0.006203120574355125\n",
            "Step 550 of 1177, Accuracy: 0.9976988636363636, Loss: 0.005965425167232752\n",
            "Step 600 of 1177, Accuracy: 0.9977864583333333, Loss: 0.005815831478685141\n",
            "Step 650 of 1177, Accuracy: 0.9978846153846154, Loss: 0.005619020666927099\n",
            "Step 700 of 1177, Accuracy: 0.9977455357142857, Loss: 0.006180320400744677\n",
            "Step 750 of 1177, Accuracy: 0.9977708333333334, Loss: 0.006145792081952095\n",
            "Step 800 of 1177, Accuracy: 0.9977734375, Loss: 0.006212285719811916\n",
            "Step 850 of 1177, Accuracy: 0.9977757352941177, Loss: 0.006329658906906843\n",
            "Step 900 of 1177, Accuracy: 0.9977430555555555, Loss: 0.00643623573705554\n",
            "Step 950 of 1177, Accuracy: 0.9977302631578947, Loss: 0.006408949848264456\n",
            "Step 1000 of 1177, Accuracy: 0.997671875, Loss: 0.00647687865421176\n",
            "Step 1050 of 1177, Accuracy: 0.9976785714285714, Loss: 0.006491322536021471\n",
            "Step 1100 of 1177, Accuracy: 0.9976704545454546, Loss: 0.006511191371828318\n",
            "Step 1150 of 1177, Accuracy: 0.9976902173913044, Loss: 0.006486875936388969\n",
            "Validation\n",
            "Training accuracy:   0.9977033772302464 | Training loss: 0.006416388787329197\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005167078925296664\n",
            "Epoch 39\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.004889649339020252\n",
            "Step 100 of 1177, Accuracy: 0.99875, Loss: 0.00513780303299427\n",
            "Step 150 of 1177, Accuracy: 0.99875, Loss: 0.0052731712348759174\n",
            "Step 200 of 1177, Accuracy: 0.998359375, Loss: 0.006402026861906052\n",
            "Step 250 of 1177, Accuracy: 0.99825, Loss: 0.006789634004235268\n",
            "Step 300 of 1177, Accuracy: 0.9980729166666666, Loss: 0.007266779895871878\n",
            "Step 350 of 1177, Accuracy: 0.9979017857142857, Loss: 0.007273158989846706\n",
            "Step 400 of 1177, Accuracy: 0.9978125, Loss: 0.006947553250938654\n",
            "Step 450 of 1177, Accuracy: 0.9978819444444444, Loss: 0.0068666692823171616\n",
            "Step 500 of 1177, Accuracy: 0.99784375, Loss: 0.006817936431616545\n",
            "Step 550 of 1177, Accuracy: 0.9977556818181819, Loss: 0.007201577536761761\n",
            "Step 600 of 1177, Accuracy: 0.9978125, Loss: 0.007322638761252165\n",
            "Step 650 of 1177, Accuracy: 0.9978365384615384, Loss: 0.0071345129981637\n",
            "Step 700 of 1177, Accuracy: 0.9977678571428571, Loss: 0.0074187093414366245\n",
            "Step 750 of 1177, Accuracy: 0.9977916666666666, Loss: 0.007441127672791481\n",
            "Step 800 of 1177, Accuracy: 0.99779296875, Loss: 0.007368508726358414\n",
            "Step 850 of 1177, Accuracy: 0.9977573529411765, Loss: 0.007424906361848116\n",
            "Step 900 of 1177, Accuracy: 0.9978125, Loss: 0.0072374832816421986\n",
            "Step 950 of 1177, Accuracy: 0.9977467105263158, Loss: 0.007509765215218067\n",
            "Step 1000 of 1177, Accuracy: 0.997734375, Loss: 0.0075711216777563095\n",
            "Step 1050 of 1177, Accuracy: 0.9977529761904762, Loss: 0.007501572370529175\n",
            "Step 1100 of 1177, Accuracy: 0.9978125, Loss: 0.007379564922302961\n",
            "Step 1150 of 1177, Accuracy: 0.9977989130434782, Loss: 0.007324632722884417\n",
            "Validation\n",
            "Training accuracy:   0.9977963041631266 | Training loss: 0.007269473746418953\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005439682863652706\n",
            "Epoch 40\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9990625, Loss: 0.004206063691526651\n",
            "Step 100 of 1177, Accuracy: 0.9978125, Loss: 0.006601275410503149\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.006201372016221285\n",
            "Step 200 of 1177, Accuracy: 0.998046875, Loss: 0.006190020591020584\n",
            "Step 250 of 1177, Accuracy: 0.998125, Loss: 0.006124211475253105\n",
            "Step 300 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006232969928532839\n",
            "Step 350 of 1177, Accuracy: 0.9978125, Loss: 0.0063562290742993355\n",
            "Step 400 of 1177, Accuracy: 0.997890625, Loss: 0.006346595473587513\n",
            "Step 450 of 1177, Accuracy: 0.9978472222222222, Loss: 0.00641075661405921\n",
            "Step 500 of 1177, Accuracy: 0.99790625, Loss: 0.006257814820855856\n",
            "Step 550 of 1177, Accuracy: 0.9978409090909091, Loss: 0.006386596243828535\n",
            "Step 600 of 1177, Accuracy: 0.9978125, Loss: 0.006344088818877935\n",
            "Step 650 of 1177, Accuracy: 0.997860576923077, Loss: 0.00656089186668396\n",
            "Step 700 of 1177, Accuracy: 0.9978571428571429, Loss: 0.006611199583858252\n",
            "Step 750 of 1177, Accuracy: 0.9978333333333333, Loss: 0.006737574934959412\n",
            "Step 800 of 1177, Accuracy: 0.9978125, Loss: 0.006675850600004196\n",
            "Step 850 of 1177, Accuracy: 0.9978308823529412, Loss: 0.006628245580941439\n",
            "Step 900 of 1177, Accuracy: 0.9978298611111112, Loss: 0.006737992167472839\n",
            "Step 950 of 1177, Accuracy: 0.9977631578947368, Loss: 0.006759297102689743\n",
            "Step 1000 of 1177, Accuracy: 0.99771875, Loss: 0.00689203105866909\n",
            "Step 1050 of 1177, Accuracy: 0.9977380952380952, Loss: 0.006778750102967024\n",
            "Step 1100 of 1177, Accuracy: 0.9977982954545455, Loss: 0.0066052088513970375\n",
            "Step 1150 of 1177, Accuracy: 0.9977717391304348, Loss: 0.006674995645880699\n",
            "Validation\n",
            "Training accuracy:   0.9977432030586236 | Training loss: 0.006718306802213192\n",
            "Validation accuracy: 1.0 | Validation loss: 0.000516720989253372\n",
            "Epoch 41\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.0035419068299233913\n",
            "Step 100 of 1177, Accuracy: 0.99765625, Loss: 0.007943416014313698\n",
            "Step 150 of 1177, Accuracy: 0.9976041666666666, Loss: 0.008423469960689545\n",
            "Step 200 of 1177, Accuracy: 0.9975, Loss: 0.008709095418453217\n",
            "Step 250 of 1177, Accuracy: 0.9975625, Loss: 0.008189246989786625\n",
            "Step 300 of 1177, Accuracy: 0.9975520833333333, Loss: 0.007789406925439835\n",
            "Step 350 of 1177, Accuracy: 0.9975446428571428, Loss: 0.007959062233567238\n",
            "Step 400 of 1177, Accuracy: 0.99765625, Loss: 0.007439429871737957\n",
            "Step 450 of 1177, Accuracy: 0.9977430555555555, Loss: 0.007359824143350124\n",
            "Step 500 of 1177, Accuracy: 0.99790625, Loss: 0.007038443349301815\n",
            "Step 550 of 1177, Accuracy: 0.9979261363636364, Loss: 0.0068579306825995445\n",
            "Step 600 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006892848759889603\n",
            "Step 650 of 1177, Accuracy: 0.9979807692307693, Loss: 0.00671133678406477\n",
            "Step 700 of 1177, Accuracy: 0.9980580357142858, Loss: 0.0065628765150904655\n",
            "Step 750 of 1177, Accuracy: 0.9980416666666667, Loss: 0.00675334595143795\n",
            "Step 800 of 1177, Accuracy: 0.998046875, Loss: 0.006663768086582422\n",
            "Step 850 of 1177, Accuracy: 0.9979595588235294, Loss: 0.006949989590793848\n",
            "Step 900 of 1177, Accuracy: 0.9978993055555555, Loss: 0.007141301408410072\n",
            "Step 950 of 1177, Accuracy: 0.9978453947368421, Loss: 0.007268803659826517\n",
            "Step 1000 of 1177, Accuracy: 0.99784375, Loss: 0.007267583627253771\n",
            "Step 1050 of 1177, Accuracy: 0.9979017857142857, Loss: 0.007164655718952417\n",
            "Step 1100 of 1177, Accuracy: 0.9978409090909091, Loss: 0.0074299960397183895\n",
            "Step 1150 of 1177, Accuracy: 0.9978668478260869, Loss: 0.007297988515347242\n",
            "Validation\n",
            "Training accuracy:   0.9978892310960068 | Training loss: 0.007313122972846031\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006587812094949186\n",
            "Epoch 42\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9978125, Loss: 0.008455395698547363\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.00721877021715045\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.00721292570233345\n",
            "Step 200 of 1177, Accuracy: 0.998046875, Loss: 0.007278128992766142\n",
            "Step 250 of 1177, Accuracy: 0.998, Loss: 0.006876043044030666\n",
            "Step 300 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006861746311187744\n",
            "Step 350 of 1177, Accuracy: 0.9981696428571428, Loss: 0.006603211630135775\n",
            "Step 400 of 1177, Accuracy: 0.9979296875, Loss: 0.007187990006059408\n",
            "Step 450 of 1177, Accuracy: 0.9980208333333334, Loss: 0.0069150859490036964\n",
            "Step 500 of 1177, Accuracy: 0.99803125, Loss: 0.006792930420488119\n",
            "Step 550 of 1177, Accuracy: 0.9980113636363637, Loss: 0.006940270308405161\n",
            "Step 600 of 1177, Accuracy: 0.99796875, Loss: 0.006940136663615704\n",
            "Step 650 of 1177, Accuracy: 0.9979807692307693, Loss: 0.006890536285936832\n",
            "Step 700 of 1177, Accuracy: 0.9980357142857142, Loss: 0.006810464896261692\n",
            "Step 750 of 1177, Accuracy: 0.9980208333333334, Loss: 0.007107884623110294\n",
            "Step 800 of 1177, Accuracy: 0.997890625, Loss: 0.0072837634943425655\n",
            "Step 850 of 1177, Accuracy: 0.9978860294117647, Loss: 0.007390713784843683\n",
            "Step 900 of 1177, Accuracy: 0.9978472222222222, Loss: 0.007405578624457121\n",
            "Step 950 of 1177, Accuracy: 0.9978125, Loss: 0.007323771715164185\n",
            "Step 1000 of 1177, Accuracy: 0.99778125, Loss: 0.007404346484690905\n",
            "Step 1050 of 1177, Accuracy: 0.997827380952381, Loss: 0.007265191525220871\n",
            "Step 1100 of 1177, Accuracy: 0.9978409090909091, Loss: 0.007315958384424448\n",
            "Step 1150 of 1177, Accuracy: 0.9978260869565218, Loss: 0.0073381573893129826\n",
            "Validation\n",
            "Training accuracy:   0.9978095794392523 | Training loss: 0.007416658569127321\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0007361349416896701\n",
            "Epoch 43\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9984375, Loss: 0.006889729294925928\n",
            "Step 100 of 1177, Accuracy: 0.998125, Loss: 0.0074494327418506145\n",
            "Step 150 of 1177, Accuracy: 0.9982291666666666, Loss: 0.00709001999348402\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.007042460609227419\n",
            "Step 250 of 1177, Accuracy: 0.9979375, Loss: 0.0071621546521782875\n",
            "Step 300 of 1177, Accuracy: 0.99796875, Loss: 0.006672996096313\n",
            "Step 350 of 1177, Accuracy: 0.998125, Loss: 0.006671084091067314\n",
            "Step 400 of 1177, Accuracy: 0.99796875, Loss: 0.006943021435290575\n",
            "Step 450 of 1177, Accuracy: 0.9979166666666667, Loss: 0.007136733736842871\n",
            "Step 500 of 1177, Accuracy: 0.998, Loss: 0.0072185625322163105\n",
            "Step 550 of 1177, Accuracy: 0.9980397727272727, Loss: 0.0071243890561163425\n",
            "Step 600 of 1177, Accuracy: 0.9980208333333334, Loss: 0.0070792874321341515\n",
            "Step 650 of 1177, Accuracy: 0.9980048076923077, Loss: 0.007038520649075508\n",
            "Step 700 of 1177, Accuracy: 0.9979910714285715, Loss: 0.006985984742641449\n",
            "Step 750 of 1177, Accuracy: 0.9980416666666667, Loss: 0.006784514524042606\n",
            "Step 800 of 1177, Accuracy: 0.99806640625, Loss: 0.006624899338930845\n",
            "Step 850 of 1177, Accuracy: 0.9980330882352941, Loss: 0.006578429136425257\n",
            "Step 900 of 1177, Accuracy: 0.9980208333333334, Loss: 0.00661058584228158\n",
            "Step 950 of 1177, Accuracy: 0.9979934210526316, Loss: 0.006608089432120323\n",
            "Step 1000 of 1177, Accuracy: 0.99796875, Loss: 0.006596870720386505\n",
            "Step 1050 of 1177, Accuracy: 0.9979761904761905, Loss: 0.00661118421703577\n",
            "Step 1100 of 1177, Accuracy: 0.9979545454545454, Loss: 0.0067336829379200935\n",
            "Step 1150 of 1177, Accuracy: 0.9979347826086956, Loss: 0.0066774808801710606\n",
            "Validation\n",
            "Training accuracy:   0.9978892310960068 | Training loss: 0.006955273915082216\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0006763539277017117\n",
            "Epoch 44\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9965625, Loss: 0.010635117068886757\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.009214818477630615\n",
            "Step 150 of 1177, Accuracy: 0.9975, Loss: 0.008881702087819576\n",
            "Step 200 of 1177, Accuracy: 0.99765625, Loss: 0.008051266893744469\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.008114408701658249\n",
            "Step 300 of 1177, Accuracy: 0.9978125, Loss: 0.0076417215168476105\n",
            "Step 350 of 1177, Accuracy: 0.9978571428571429, Loss: 0.0072643267922103405\n",
            "Step 400 of 1177, Accuracy: 0.9978125, Loss: 0.006924204993993044\n",
            "Step 450 of 1177, Accuracy: 0.9978125, Loss: 0.00683820154517889\n",
            "Step 500 of 1177, Accuracy: 0.99790625, Loss: 0.006562172435224056\n",
            "Step 550 of 1177, Accuracy: 0.9979545454545454, Loss: 0.006631127558648586\n",
            "Step 600 of 1177, Accuracy: 0.9978645833333334, Loss: 0.00744618009775877\n",
            "Step 650 of 1177, Accuracy: 0.9979086538461538, Loss: 0.007457294501364231\n",
            "Step 700 of 1177, Accuracy: 0.99796875, Loss: 0.007198721170425415\n",
            "Step 750 of 1177, Accuracy: 0.9979583333333333, Loss: 0.007052289322018623\n",
            "Step 800 of 1177, Accuracy: 0.99794921875, Loss: 0.006897813640534878\n",
            "Step 850 of 1177, Accuracy: 0.9979411764705882, Loss: 0.006777258589863777\n",
            "Step 900 of 1177, Accuracy: 0.9978993055555555, Loss: 0.006694605108350515\n",
            "Step 950 of 1177, Accuracy: 0.9978618421052632, Loss: 0.006908127572387457\n",
            "Step 1000 of 1177, Accuracy: 0.997890625, Loss: 0.006789861246943474\n",
            "Step 1050 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006624087691307068\n",
            "Step 1100 of 1177, Accuracy: 0.9979119318181818, Loss: 0.0067715332843363285\n",
            "Step 1150 of 1177, Accuracy: 0.9978940217391304, Loss: 0.006749158259481192\n",
            "Validation\n",
            "Training accuracy:   0.9979025063721325 | Training loss: 0.006728907581418753\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005341924261301756\n",
            "Epoch 45\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9971875, Loss: 0.005868235137313604\n",
            "Step 100 of 1177, Accuracy: 0.99796875, Loss: 0.005720257759094238\n",
            "Step 150 of 1177, Accuracy: 0.9977083333333333, Loss: 0.006173836532980204\n",
            "Step 200 of 1177, Accuracy: 0.9978125, Loss: 0.006036809645593166\n",
            "Step 250 of 1177, Accuracy: 0.9976875, Loss: 0.0074697257950901985\n",
            "Step 300 of 1177, Accuracy: 0.9975, Loss: 0.007616995368152857\n",
            "Step 350 of 1177, Accuracy: 0.9976785714285714, Loss: 0.00734336581081152\n",
            "Step 400 of 1177, Accuracy: 0.997578125, Loss: 0.0074720000848174095\n",
            "Step 450 of 1177, Accuracy: 0.9975347222222222, Loss: 0.007830620743334293\n",
            "Step 500 of 1177, Accuracy: 0.99765625, Loss: 0.007827558554708958\n",
            "Step 550 of 1177, Accuracy: 0.9977272727272727, Loss: 0.007497961632907391\n",
            "Step 600 of 1177, Accuracy: 0.997734375, Loss: 0.0074913399294018745\n",
            "Step 650 of 1177, Accuracy: 0.9978125, Loss: 0.007314418442547321\n",
            "Step 700 of 1177, Accuracy: 0.9978125, Loss: 0.007241524290293455\n",
            "Step 750 of 1177, Accuracy: 0.99775, Loss: 0.007374271284788847\n",
            "Step 800 of 1177, Accuracy: 0.99783203125, Loss: 0.007209115196019411\n",
            "Step 850 of 1177, Accuracy: 0.9977941176470588, Loss: 0.007367583457380533\n",
            "Step 900 of 1177, Accuracy: 0.9978125, Loss: 0.0072365738451480865\n",
            "Step 950 of 1177, Accuracy: 0.997796052631579, Loss: 0.007150532212108374\n",
            "Step 1000 of 1177, Accuracy: 0.997796875, Loss: 0.007076673675328493\n",
            "Step 1050 of 1177, Accuracy: 0.9977232142857143, Loss: 0.007153945509344339\n",
            "Step 1100 of 1177, Accuracy: 0.9977698863636364, Loss: 0.007001139223575592\n",
            "Step 1150 of 1177, Accuracy: 0.9977445652173913, Loss: 0.007026643492281437\n",
            "Validation\n",
            "Training accuracy:   0.9977432030586236 | Training loss: 0.006949821021407843\n",
            "Validation accuracy: 1.0 | Validation loss: 0.00040035511483438313\n",
            "saving with loss of 0.00040035511483438313 improved over previous 0.00040035511483438313\n",
            "Epoch 46\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9984375, Loss: 0.0032263759057968855\n",
            "Step 100 of 1177, Accuracy: 0.9990625, Loss: 0.0024286936968564987\n",
            "Step 150 of 1177, Accuracy: 0.99875, Loss: 0.004363726358860731\n",
            "Step 200 of 1177, Accuracy: 0.998515625, Loss: 0.0064020343124866486\n",
            "Step 250 of 1177, Accuracy: 0.998375, Loss: 0.006297395098954439\n",
            "Step 300 of 1177, Accuracy: 0.99828125, Loss: 0.00682606128975749\n",
            "Step 350 of 1177, Accuracy: 0.9981696428571428, Loss: 0.00677356356754899\n",
            "Step 400 of 1177, Accuracy: 0.998125, Loss: 0.007023494690656662\n",
            "Step 450 of 1177, Accuracy: 0.9980902777777778, Loss: 0.006614489480853081\n",
            "Step 500 of 1177, Accuracy: 0.99815625, Loss: 0.0063715968281030655\n",
            "Step 550 of 1177, Accuracy: 0.9979261363636364, Loss: 0.006711320020258427\n",
            "Step 600 of 1177, Accuracy: 0.9978645833333334, Loss: 0.006613556761294603\n",
            "Step 650 of 1177, Accuracy: 0.9979326923076923, Loss: 0.006400886457413435\n",
            "Step 700 of 1177, Accuracy: 0.99796875, Loss: 0.006384618580341339\n",
            "Step 750 of 1177, Accuracy: 0.998, Loss: 0.006412713788449764\n",
            "Step 800 of 1177, Accuracy: 0.9979296875, Loss: 0.006784545723348856\n",
            "Step 850 of 1177, Accuracy: 0.9979227941176471, Loss: 0.0069460258819162846\n",
            "Step 900 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006965974811464548\n",
            "Step 950 of 1177, Accuracy: 0.9979769736842106, Loss: 0.006899528671056032\n",
            "Step 1000 of 1177, Accuracy: 0.99796875, Loss: 0.006863977760076523\n",
            "Step 1050 of 1177, Accuracy: 0.9980208333333334, Loss: 0.0067850518971681595\n",
            "Step 1100 of 1177, Accuracy: 0.99796875, Loss: 0.006769123021513224\n",
            "Step 1150 of 1177, Accuracy: 0.9978940217391304, Loss: 0.006906887050718069\n",
            "Validation\n",
            "Training accuracy:   0.9979157816482583 | Training loss: 0.006830628030002117\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005323090008459985\n",
            "Epoch 47\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9971875, Loss: 0.008730286732316017\n",
            "Step 100 of 1177, Accuracy: 0.9975, Loss: 0.007355140522122383\n",
            "Step 150 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006311207544058561\n",
            "Step 200 of 1177, Accuracy: 0.998046875, Loss: 0.006196639500558376\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.006631874013692141\n",
            "Step 300 of 1177, Accuracy: 0.9978645833333334, Loss: 0.0068455711007118225\n",
            "Step 350 of 1177, Accuracy: 0.9977678571428571, Loss: 0.00699209701269865\n",
            "Step 400 of 1177, Accuracy: 0.99796875, Loss: 0.006659761071205139\n",
            "Step 450 of 1177, Accuracy: 0.9980208333333334, Loss: 0.0067021725699305534\n",
            "Step 500 of 1177, Accuracy: 0.998125, Loss: 0.006648554466664791\n",
            "Step 550 of 1177, Accuracy: 0.998125, Loss: 0.006678251549601555\n",
            "Step 600 of 1177, Accuracy: 0.99796875, Loss: 0.00696528097614646\n",
            "Step 650 of 1177, Accuracy: 0.9979326923076923, Loss: 0.007366611156612635\n",
            "Step 700 of 1177, Accuracy: 0.9979910714285715, Loss: 0.007353479508310556\n",
            "Step 750 of 1177, Accuracy: 0.9980208333333334, Loss: 0.007422753609716892\n",
            "Step 800 of 1177, Accuracy: 0.9980078125, Loss: 0.0074145919643342495\n",
            "Step 850 of 1177, Accuracy: 0.9980330882352941, Loss: 0.00725844269618392\n",
            "Step 900 of 1177, Accuracy: 0.9980208333333334, Loss: 0.007165502291172743\n",
            "Step 950 of 1177, Accuracy: 0.9980263157894737, Loss: 0.00702653918415308\n",
            "Step 1000 of 1177, Accuracy: 0.99803125, Loss: 0.006950534880161285\n",
            "Step 1050 of 1177, Accuracy: 0.9980208333333334, Loss: 0.007008757907897234\n",
            "Step 1100 of 1177, Accuracy: 0.9980681818181818, Loss: 0.006898484192788601\n",
            "Step 1150 of 1177, Accuracy: 0.9980163043478261, Loss: 0.007003977429121733\n",
            "Validation\n",
            "Training accuracy:   0.9980087085811384 | Training loss: 0.007037108298391104\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0010124086402356625\n",
            "Epoch 48\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.998125, Loss: 0.008735821582376957\n",
            "Step 100 of 1177, Accuracy: 0.998125, Loss: 0.006577230524271727\n",
            "Step 150 of 1177, Accuracy: 0.998125, Loss: 0.006353804375976324\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.007036362309008837\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.006457613315433264\n",
            "Step 300 of 1177, Accuracy: 0.99796875, Loss: 0.006578830070793629\n",
            "Step 350 of 1177, Accuracy: 0.9979910714285715, Loss: 0.006908251903951168\n",
            "Step 400 of 1177, Accuracy: 0.998125, Loss: 0.006902675144374371\n",
            "Step 450 of 1177, Accuracy: 0.9981597222222223, Loss: 0.006951523944735527\n",
            "Step 500 of 1177, Accuracy: 0.998125, Loss: 0.006750105414539576\n",
            "Step 550 of 1177, Accuracy: 0.9980681818181818, Loss: 0.006859494373202324\n",
            "Step 600 of 1177, Accuracy: 0.998046875, Loss: 0.007172937970608473\n",
            "Step 650 of 1177, Accuracy: 0.9980048076923077, Loss: 0.007498933468014002\n",
            "Step 700 of 1177, Accuracy: 0.9979241071428572, Loss: 0.007636657916009426\n",
            "Step 750 of 1177, Accuracy: 0.9979583333333333, Loss: 0.00759464455768466\n",
            "Step 800 of 1177, Accuracy: 0.99802734375, Loss: 0.007317755836993456\n",
            "Step 850 of 1177, Accuracy: 0.9981066176470588, Loss: 0.007222872227430344\n",
            "Step 900 of 1177, Accuracy: 0.9981076388888889, Loss: 0.007078383583575487\n",
            "Step 950 of 1177, Accuracy: 0.998141447368421, Loss: 0.006892149802297354\n",
            "Step 1000 of 1177, Accuracy: 0.998125, Loss: 0.0069753751158714294\n",
            "Step 1050 of 1177, Accuracy: 0.9981696428571428, Loss: 0.006828295066952705\n",
            "Step 1100 of 1177, Accuracy: 0.9980823863636363, Loss: 0.0069390456192195415\n",
            "Step 1150 of 1177, Accuracy: 0.9980978260869565, Loss: 0.006894715595990419\n",
            "Validation\n",
            "Training accuracy:   0.9980733149249504 | Training loss: 0.0069170305505394936\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0004295844701118767\n",
            "Epoch 49\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.99875, Loss: 0.004252806305885315\n",
            "Step 100 of 1177, Accuracy: 0.99828125, Loss: 0.00588822178542614\n",
            "Step 150 of 1177, Accuracy: 0.9979166666666667, Loss: 0.006076632533222437\n",
            "Step 200 of 1177, Accuracy: 0.998125, Loss: 0.00548525108024478\n",
            "Step 250 of 1177, Accuracy: 0.997875, Loss: 0.007057978771626949\n",
            "Step 300 of 1177, Accuracy: 0.9980208333333334, Loss: 0.00654908362776041\n",
            "Step 350 of 1177, Accuracy: 0.9981696428571428, Loss: 0.006144979503005743\n",
            "Step 400 of 1177, Accuracy: 0.998046875, Loss: 0.006546173244714737\n",
            "Step 450 of 1177, Accuracy: 0.998125, Loss: 0.006427245680242777\n",
            "Step 500 of 1177, Accuracy: 0.99796875, Loss: 0.006666894070804119\n",
            "Step 550 of 1177, Accuracy: 0.9979829545454545, Loss: 0.006901619955897331\n",
            "Step 600 of 1177, Accuracy: 0.998046875, Loss: 0.007012892514467239\n",
            "Step 650 of 1177, Accuracy: 0.9979807692307693, Loss: 0.007229238748550415\n",
            "Step 700 of 1177, Accuracy: 0.99796875, Loss: 0.00720257218927145\n",
            "Step 750 of 1177, Accuracy: 0.9979583333333333, Loss: 0.007079169619828463\n",
            "Step 800 of 1177, Accuracy: 0.99794921875, Loss: 0.007048036437481642\n",
            "Step 850 of 1177, Accuracy: 0.9978860294117647, Loss: 0.00709348451346159\n",
            "Step 900 of 1177, Accuracy: 0.9979340277777777, Loss: 0.006984767969697714\n",
            "Step 950 of 1177, Accuracy: 0.9979769736842106, Loss: 0.006811982020735741\n",
            "Step 1000 of 1177, Accuracy: 0.99796875, Loss: 0.006856719497591257\n",
            "Step 1050 of 1177, Accuracy: 0.9979613095238096, Loss: 0.006923197768628597\n",
            "Step 1100 of 1177, Accuracy: 0.9980113636363637, Loss: 0.006752029061317444\n",
            "Step 1150 of 1177, Accuracy: 0.9980027173913043, Loss: 0.006881726905703545\n",
            "Validation\n",
            "Training accuracy:   0.9980087085811384 | Training loss: 0.00680274423211813\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005254616844467819\n",
            "Epoch 50\n",
            "Training\n",
            "Step 50 of 1177, Accuracy: 0.9975, Loss: 0.0061702425591647625\n",
            "Step 100 of 1177, Accuracy: 0.99734375, Loss: 0.007604851853102446\n",
            "Step 150 of 1177, Accuracy: 0.9976041666666666, Loss: 0.006665166467428207\n",
            "Step 200 of 1177, Accuracy: 0.99796875, Loss: 0.006009278353303671\n",
            "Step 250 of 1177, Accuracy: 0.9979375, Loss: 0.005950018297880888\n",
            "Step 300 of 1177, Accuracy: 0.9980208333333334, Loss: 0.0056824469938874245\n",
            "Step 350 of 1177, Accuracy: 0.9982142857142857, Loss: 0.005198078695684671\n",
            "Step 400 of 1177, Accuracy: 0.99828125, Loss: 0.005047370679676533\n",
            "Step 450 of 1177, Accuracy: 0.9981944444444445, Loss: 0.005448156036436558\n",
            "Step 500 of 1177, Accuracy: 0.99809375, Loss: 0.005547183100134134\n",
            "Step 550 of 1177, Accuracy: 0.9980965909090909, Loss: 0.005712016485631466\n",
            "Step 600 of 1177, Accuracy: 0.998046875, Loss: 0.005741147790104151\n",
            "Step 650 of 1177, Accuracy: 0.9981730769230769, Loss: 0.005449126474559307\n",
            "Step 700 of 1177, Accuracy: 0.9980803571428571, Loss: 0.005663768853992224\n",
            "Step 750 of 1177, Accuracy: 0.9981041666666667, Loss: 0.005628431215882301\n",
            "Step 800 of 1177, Accuracy: 0.9981640625, Loss: 0.005482550710439682\n",
            "Step 850 of 1177, Accuracy: 0.998125, Loss: 0.005521977320313454\n",
            "Step 900 of 1177, Accuracy: 0.9981076388888889, Loss: 0.005679658614099026\n",
            "Step 950 of 1177, Accuracy: 0.9980592105263157, Loss: 0.005987463518977165\n",
            "Step 1000 of 1177, Accuracy: 0.998046875, Loss: 0.005971843376755714\n",
            "Step 1050 of 1177, Accuracy: 0.9980208333333334, Loss: 0.006121441256254911\n",
            "Step 1100 of 1177, Accuracy: 0.9979971590909091, Loss: 0.006079826503992081\n",
            "Step 1150 of 1177, Accuracy: 0.9979483695652174, Loss: 0.0061713336035609245\n",
            "Validation\n",
            "Training accuracy:   0.9979423322005098 | Training loss: 0.006230965256690979\n",
            "Validation accuracy: 1.0 | Validation loss: 0.0005689194076694548\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponv_wcrdFcs",
        "outputId": "af2c9ed0-f72f-495f-8fb3-539a56c44ee2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "source": [
        "net.eval()\n",
        "preds = net(torch.from_numpy(x_valid).to(device))\n",
        "preds = preds.argmax(1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7kBuDCZ3fsar"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "source": [
        "accuracy, macro_f1 = get_metrics(y_valid, preds)\n",
        "print(f\"Accuracy: {accuracy} Macro F1: {macro_f1}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9982841455044612 Macro F1: 0.9964785468190034\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKq1u9a5gLRF",
        "outputId": "fe774b53-7b82-4f94-f948-5361e93eb1ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "source": [
        "print(confusion_matrix(y_valid, preds))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[37467    67]\n",
            " [    8  6168]]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sdN25SVsJ4m",
        "outputId": "bc3e649b-c959-47ba-97c4-eaa67bc30218"
      }
    }
  ]
}